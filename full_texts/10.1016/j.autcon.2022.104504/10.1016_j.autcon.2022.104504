<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/article/pii/S0926580522003776</prism:url><dc:identifier>doi:10.1016/j.autcon.2022.104504</dc:identifier><eid>1-s2.0-S0926580522003776</eid><prism:doi>10.1016/j.autcon.2022.104504</prism:doi><pii>S0926-5805(22)00377-6</pii><dc:title>Deep learning for estimating pavement roughness using synthetic aperture radar data </dc:title><prism:publicationName>Automation in Construction</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><pubType>fla</pubType><prism:issn>09265805</prism:issn><prism:volume>142</prism:volume><prism:startingPage>104504</prism:startingPage><prism:pageRange>104504</prism:pageRange><articleNumber>104504</articleNumber><dc:format>text/xml</dc:format><prism:coverDate>2022-10-31</prism:coverDate><prism:coverDisplayDate>October 2022</prism:coverDisplayDate><prism:copyright>© 2022 Elsevier B.V. All rights reserved.</prism:copyright><prism:publisher>Elsevier B.V.</prism:publisher><dc:creator>Bashar, Mohammad Z.</dc:creator><dc:creator>Torres-Machi, Cristina</dc:creator><dc:description>
                  Because of the high costs of ground-based pavement condition methods used to monitor pavement condition, transportation agencies often limit distress surveys to their major roads. As a result, the condition of local and ancillary roads remains unknown to decision-makers. This study addresses this gap by exploring the capabilities of publicly available Synthetic Aperture Radar (SAR) data to estimate pavement roughness. This paper introduces a novel framework to address the challenges of using SAR images in evaluating pavement condition. The trunk highway network in Minnesota is analyzed to develop deep learning models that predict International Roughness Index (IRI) and associated prediction intervals. This analysis found that SAR images have a strong potential in quantifying pavement condition. The deep learning models were able to predict IRI with a mean absolute error of 14.6 in./miles and provide intervals of pavement condition that capture actual IRI values with an accuracy of 81%.
               </dc:description><openaccess>0</openaccess><openaccessArticle>false</openaccessArticle><openaccessType/><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType/><openaccessUserLicense/><dcterms:subject>Pavement</dcterms:subject><dcterms:subject>IRI</dcterms:subject><dcterms:subject>Deep learning</dcterms:subject><dcterms:subject>Image processing</dcterms:subject><dcterms:subject>Satellite data</dcterms:subject><dcterms:subject>Remote sensing</dcterms:subject><link href="https://api.elsevier.com/content/article/pii/S0926580522003776" rel="self"/><link href="https://www.sciencedirect.com/science/article/pii/S0926580522003776" rel="scidir"/></coredata><objects><object ref="gr15" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="587" height="300" size="36348">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr15.jpg?httpAccept=%2A%2F%2A</object><object ref="gr16" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="355" height="250" size="26832">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr16.jpg?httpAccept=%2A%2F%2A</object><object ref="gr13" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="587" height="297" size="52990">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr13.jpg?httpAccept=%2A%2F%2A</object><object ref="gr14" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="587" height="293" size="39818">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr14.jpg?httpAccept=%2A%2F%2A</object><object ref="gr11" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="498" height="228" size="24153">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr11.jpg?httpAccept=%2A%2F%2A</object><object ref="gr12" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="389" height="184" size="18078">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr12.jpg?httpAccept=%2A%2F%2A</object><object ref="gr10" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="533" height="258" size="77555">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr10.jpg?httpAccept=%2A%2F%2A</object><object ref="gr1" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="538" height="193" size="18598">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr1.jpg?httpAccept=%2A%2F%2A</object><object ref="gr17" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="355" height="252" size="15603">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr17.jpg?httpAccept=%2A%2F%2A</object><object ref="gr18" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="320" height="325" size="24354">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr18.jpg?httpAccept=%2A%2F%2A</object><object ref="gr9" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="389" height="370" size="60673">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr9.jpg?httpAccept=%2A%2F%2A</object><object ref="gr8" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="533" height="193" size="23139">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr8.jpg?httpAccept=%2A%2F%2A</object><object ref="gr7" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="498" height="274" size="26434">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr7.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="533" height="250" size="23320">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr6.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="389" height="179" size="28682">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr5.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="498" height="83" size="13105">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr4.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="711" height="445" size="131965">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr3.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="498" height="170" size="11587">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr2.jpg?httpAccept=%2A%2F%2A</object><object ref="gr15" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="112" size="6217">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr15.sml?httpAccept=%2A%2F%2A</object><object ref="gr16" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="154" size="7936">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr16.sml?httpAccept=%2A%2F%2A</object><object ref="gr13" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="111" size="7347">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr13.sml?httpAccept=%2A%2F%2A</object><object ref="gr14" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="109" size="5718">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr14.sml?httpAccept=%2A%2F%2A</object><object ref="gr11" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="100" size="4377">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr11.sml?httpAccept=%2A%2F%2A</object><object ref="gr12" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="103" size="9245">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr12.sml?httpAccept=%2A%2F%2A</object><object ref="gr10" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="106" size="18010">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr10.sml?httpAccept=%2A%2F%2A</object><object ref="gr1" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="78" size="2634">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr1.sml?httpAccept=%2A%2F%2A</object><object ref="gr17" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="155" size="5684">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr17.sml?httpAccept=%2A%2F%2A</object><object ref="gr18" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="161" height="164" size="11091">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr18.sml?httpAccept=%2A%2F%2A</object><object ref="gr9" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="172" height="164" size="21382">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr9.sml?httpAccept=%2A%2F%2A</object><object ref="gr8" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="79" size="4414">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr8.sml?httpAccept=%2A%2F%2A</object><object ref="gr7" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="121" size="4526">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr7.sml?httpAccept=%2A%2F%2A</object><object ref="gr6" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="103" size="3583">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr6.sml?httpAccept=%2A%2F%2A</object><object ref="gr5" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="101" size="16673">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr5.sml?httpAccept=%2A%2F%2A</object><object ref="gr4" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="37" size="5943">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr4.sml?httpAccept=%2A%2F%2A</object><object ref="gr3" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="137" size="11065">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr3.sml?httpAccept=%2A%2F%2A</object><object ref="gr2" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="75" size="3019">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr2.sml?httpAccept=%2A%2F%2A</object><object ref="gr15" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1559" height="796" size="120507">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr15_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr16" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="945" height="666" size="99376">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr16_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr13" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1559" height="789" size="177374">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr13_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr14" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1559" height="778" size="137888">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr14_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr11" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1323" height="606" size="74130">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr11_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr12" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1722" height="813" size="145868">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr12_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr10" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1417" height="685" size="515095">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr10_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr1" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2384" height="854" size="148729">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr1_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr17" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="945" height="670" size="53329">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr17_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr18" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="850" height="864" size="86995">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr18_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr9" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1033" height="982" size="288818">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr9_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr8" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1417" height="512" size="72391">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr8_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr7" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2205" height="1215" size="163299">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr7_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2362" height="1108" size="151186">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr6_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1722" height="792" size="525015">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr5_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2205" height="369" size="108054">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr4_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1890" height="1183" size="453944">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr3_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2205" height="751" size="95517">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-gr2_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="si1" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="4315">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si1.svg?httpAccept=%2A%2F%2A</object><object ref="si2" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="5996">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si2.svg?httpAccept=%2A%2F%2A</object><object ref="si3" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="10907">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si3.svg?httpAccept=%2A%2F%2A</object><object ref="si4" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="10878">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si4.svg?httpAccept=%2A%2F%2A</object><object ref="si5" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="9683">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si5.svg?httpAccept=%2A%2F%2A</object><object ref="si6" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="11786">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si6.svg?httpAccept=%2A%2F%2A</object><object ref="si7" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="12894">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si7.svg?httpAccept=%2A%2F%2A</object><object ref="si8" category="thumbnail" type="ALTIMG" multimediatype="Scalable Vector Graphics file" mimetype="image/svg+xml" size="11483">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-si8.svg?httpAccept=%2A%2F%2A</object><object ref="am" category="standard" type="AAM-PDF" multimediatype="Acrobat PDF file" mimetype="application/pdf" size="2725098">https://api.elsevier.com/content/object/eid/1-s2.0-S0926580522003776-am.pdf?httpAccept=%2A%2F%2A</object></objects><scopus-id>85135413405</scopus-id><scopus-eid>2-s2.0-85135413405</scopus-eid><link href="https://api.elsevier.com/content/abstract/scopus_id/85135413405" rel="abstract"/><originalText><xocs:doc xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://null/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd">
      <xocs:content-family>serial</xocs:content-family>
      <xocs:content-type>JL</xocs:content-type>
      <xocs:cid>271427</xocs:cid>
      <xocs:ssids>
         <xocs:ssid type="alllist">291210</xocs:ssid>
         <xocs:ssid type="subj">291817</xocs:ssid>
         <xocs:ssid type="subj">291881</xocs:ssid>
         <xocs:ssid type="subj">291883</xocs:ssid>
         <xocs:ssid type="content">31</xocs:ssid>
      </xocs:ssids>
      <xocs:srctitle>Automation in Construction</xocs:srctitle>
      <xocs:normalized-srctitle>AUTOMATIONINCONSTRUCTION</xocs:normalized-srctitle>
      <xocs:orig-load-date yyyymmdd="20220803">2022-08-03</xocs:orig-load-date>
      <xocs:available-online-date yyyymmdd="20220803">2022-08-03</xocs:available-online-date>
      <xocs:vor-load-date yyyymmdd="20220803">2022-08-03</xocs:vor-load-date>
      <xocs:vor-available-online-date yyyymmdd="20220803">2022-08-03</xocs:vor-available-online-date>
      <xocs:ew-transaction-id>2023-08-17T22:58:28</xocs:ew-transaction-id>
      <xocs:eid>1-s2.0-S0926580522003776</xocs:eid>
      <xocs:pii-formatted>S0926-5805(22)00377-6</xocs:pii-formatted>
      <xocs:pii-unformatted>S0926580522003776</xocs:pii-unformatted>
      <xocs:doi>10.1016/j.autcon.2022.104504</xocs:doi>
      <xocs:item-stage>S300</xocs:item-stage>
      <xocs:item-version-number>S300.1</xocs:item-version-number>
      <xocs:item-weight>FULL-TEXT</xocs:item-weight>
      <xocs:hub-eid>1-s2.0-S0926580522X00083</xocs:hub-eid>
      <xocs:timestamp yyyymmdd="20230817">2023-08-17T22:21:12.883703Z</xocs:timestamp>
      <xocs:dco>0</xocs:dco>
      <xocs:tomb>0</xocs:tomb>
      <xocs:date-search-begin>20221001</xocs:date-search-begin>
      <xocs:date-search-end>20221031</xocs:date-search-end>
      <xocs:year-nav>2022</xocs:year-nav>
      <xocs:indexeddate epoch="1659503480">2022-08-03T05:11:20.062387Z</xocs:indexeddate>
      <xocs:articleinfo>articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst primabst ref</xocs:articleinfo>
      <xocs:issns>
         <xocs:issn-primary-formatted>0926-5805</xocs:issn-primary-formatted>
         <xocs:issn-primary-unformatted>09265805</xocs:issn-primary-unformatted>
      </xocs:issns>
      <xocs:crossmark is-crossmark="1">true</xocs:crossmark>
      <xocs:vol-first>142</xocs:vol-first>
      <xocs:volume-list>
         <xocs:volume>142</xocs:volume>
      </xocs:volume-list>
      <xocs:suppl>C</xocs:suppl>
      <xocs:vol-iss-suppl-text>Volume 142</xocs:vol-iss-suppl-text>
      <xocs:sort-order>35</xocs:sort-order>
      <xocs:first-fp>104504</xocs:first-fp>
      <xocs:article-number>104504</xocs:article-number>
      <xocs:pages>
         <xocs:first-page>104504</xocs:first-page>
      </xocs:pages>
      <xocs:cover-date-orig>
         <xocs:start-date>202210</xocs:start-date>
      </xocs:cover-date-orig>
      <xocs:cover-date-text>October 2022</xocs:cover-date-text>
      <xocs:cover-date-start>2022-10-01</xocs:cover-date-start>
      <xocs:cover-date-end>2022-10-31</xocs:cover-date-end>
      <xocs:cover-date-year>2022</xocs:cover-date-year>
      <xocs:document-type>article</xocs:document-type>
      <xocs:document-subtype>fla</xocs:document-subtype>
      <xocs:copyright-line>© 2022 Elsevier B.V. All rights reserved.</xocs:copyright-line>
      <xocs:normalized-article-title>DEEPLEARNINGFORESTIMATINGPAVEMENTROUGHNESSUSINGSYNTHETICAPERTURERADARDATA</xocs:normalized-article-title>
      <xocs:normalized-first-auth-surname>BASHAR</xocs:normalized-first-auth-surname>
      <xocs:normalized-first-auth-initial>M</xocs:normalized-first-auth-initial>
      <xocs:item-toc>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>1</xocs:item-toc-label>
            <xocs:item-toc-section-title>Introduction</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>1.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Objectives</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>2</xocs:item-toc-label>
            <xocs:item-toc-section-title>Challenges in using SAR to monitor pavements</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>3</xocs:item-toc-label>
            <xocs:item-toc-section-title>Proposed framework</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>3.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Data processing</xocs:item-toc-section-title>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>3.1.1</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Post-process SAR image</xocs:item-toc-section-title>
                  <xocs:item-toc-entry ref-elem="ce:sections">
                     <xocs:item-toc-label>3.1.1.1</xocs:item-toc-label>
                     <xocs:item-toc-section-title>Select effective polarization</xocs:item-toc-section-title>
                  </xocs:item-toc-entry>
                  <xocs:item-toc-entry ref-elem="ce:sections">
                     <xocs:item-toc-label>3.1.1.2</xocs:item-toc-label>
                     <xocs:item-toc-section-title>Speckle filtering</xocs:item-toc-section-title>
                  </xocs:item-toc-entry>
                  <xocs:item-toc-entry ref-elem="ce:sections">
                     <xocs:item-toc-label>3.1.1.3</xocs:item-toc-label>
                     <xocs:item-toc-section-title>Radiometric terrain correction</xocs:item-toc-section-title>
                  </xocs:item-toc-entry>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>3.1.2</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Remove traffic noise</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>3.1.3</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Extract SAR responses</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>3.1.4</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Compile final dataset</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>3.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Deep learning tool</xocs:item-toc-section-title>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>3.2.1</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Model development</xocs:item-toc-section-title>
                  <xocs:item-toc-entry ref-elem="ce:sections">
                     <xocs:item-toc-label>3.2.1.1</xocs:item-toc-label>
                     <xocs:item-toc-section-title>IRI prediction</xocs:item-toc-section-title>
                  </xocs:item-toc-entry>
                  <xocs:item-toc-entry ref-elem="ce:sections">
                     <xocs:item-toc-label>3.2.1.2</xocs:item-toc-label>
                     <xocs:item-toc-section-title>Prediction intervals</xocs:item-toc-section-title>
                  </xocs:item-toc-entry>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>3.2.2</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Model testing</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>4</xocs:item-toc-label>
            <xocs:item-toc-section-title>Case study</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>4.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Pavement condition and feature data</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>4.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>SAR imagery</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>5</xocs:item-toc-label>
            <xocs:item-toc-section-title>Results</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>5.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Data processing</xocs:item-toc-section-title>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.1</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Selection of appropriate polarization</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.2</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Speckle suppression performance</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.3</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Effect of radiometric terrain correction</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.4</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Seasonal variability of SAR response</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.1.5</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Removing traffic noise</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>5.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Deep learning tool</xocs:item-toc-section-title>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.2.1</xocs:item-toc-label>
                  <xocs:item-toc-section-title>IRI prediction</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.2.2</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Prediction intervals</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
               <xocs:item-toc-entry ref-elem="ce:sections">
                  <xocs:item-toc-label>5.2.3</xocs:item-toc-label>
                  <xocs:item-toc-section-title>Classification accuracy</xocs:item-toc-section-title>
               </xocs:item-toc-entry>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>5.3</xocs:item-toc-label>
               <xocs:item-toc-section-title>Model deployment</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-label>6</xocs:item-toc-label>
            <xocs:item-toc-section-title>Conclusions and recommendations</xocs:item-toc-section-title>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>6.1</xocs:item-toc-label>
               <xocs:item-toc-section-title>Conclusions</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>6.2</xocs:item-toc-label>
               <xocs:item-toc-section-title>Recommendations</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
            <xocs:item-toc-entry ref-elem="ce:sections">
               <xocs:item-toc-label>6.3</xocs:item-toc-label>
               <xocs:item-toc-section-title>Limitations and future research</xocs:item-toc-section-title>
            </xocs:item-toc-entry>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:sections">
            <xocs:item-toc-section-title>Funding</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:acknowledgment">
            <xocs:item-toc-section-title>Acknowledgements</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
         <xocs:item-toc-entry ref-elem="ce:bibliography">
            <xocs:item-toc-section-title>References</xocs:item-toc-section-title>
         </xocs:item-toc-entry>
      </xocs:item-toc>
      <xocs:references>
         <xocs:ref-info refid="rf0005">
            <xocs:ref-normalized-surname>ASCE</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>REPORTCARDFORAMERICASINFRASTRUCTURE2021</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0010">
            <xocs:ref-normalized-surname>TRIP</xocs:ref-normalized-surname>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0015">
            <xocs:ref-normalized-surname>FHWA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2016</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>HIGHWAYPERFORMANCEMONITORINGSYSTEMFIELDMANUAL</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0020">
            <xocs:ref-normalized-surname>SHAHI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2015</xocs:ref-pub-year>
            <xocs:ref-first-fp>27</xocs:ref-first-fp>
            <xocs:ref-last-lp>33</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>K</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0025">
            <xocs:ref-normalized-surname>METTAS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2015</xocs:ref-pub-year>
            <xocs:ref-first-fp>95350S</xocs:ref-first-fp>
            <xocs:ref-normalized-initial>C</xocs:ref-normalized-initial>
            <xocs:ref-normalized-srctitle>THIRDINTCONFREMOTESENSGEOINFENVIRON</xocs:ref-normalized-srctitle>
            <xocs:ref-normalized-article-title>MONITORINGASPHALTPAVEMENTDAMAGESUSINGREMOTESENSINGTECHNIQUES</xocs:ref-normalized-article-title>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0030">
            <xocs:ref-normalized-surname>LI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2017</xocs:ref-pub-year>
            <xocs:ref-first-fp>1</xocs:ref-first-fp>
            <xocs:ref-last-lp>11</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>M</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0035">
            <xocs:ref-normalized-surname>BASHAR</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-first-fp>226</xocs:ref-first-fp>
            <xocs:ref-last-lp>237</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>M</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0040">
            <xocs:ref-normalized-surname>KOCH</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2015</xocs:ref-pub-year>
            <xocs:ref-first-fp>196</xocs:ref-first-fp>
            <xocs:ref-last-lp>210</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>C</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0045">
            <xocs:ref-normalized-surname>LI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2022</xocs:ref-pub-year>
            <xocs:ref-article-number>104111</xocs:ref-article-number>
            <xocs:ref-normalized-initial>J</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0050">
            <xocs:ref-normalized-surname>TONG</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2018</xocs:ref-pub-year>
            <xocs:ref-first-fp>1056</xocs:ref-first-fp>
            <xocs:ref-last-lp>1072</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>Z</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0055">
            <xocs:ref-normalized-surname>BATRAKOVA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2018</xocs:ref-pub-year>
            <xocs:ref-first-fp>55</xocs:ref-first-fp>
            <xocs:ref-last-lp>71</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>A</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0060">
            <xocs:ref-normalized-surname>BATRAKOV</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>D</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0065">
            <xocs:ref-normalized-surname>TONG</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2017</xocs:ref-pub-year>
            <xocs:ref-first-fp>775</xocs:ref-first-fp>
            <xocs:ref-last-lp>787</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>Z</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0070">
            <xocs:ref-normalized-surname>MA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-first-fp>938</xocs:ref-first-fp>
            <xocs:ref-last-lp>947</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0075">
            <xocs:ref-normalized-surname>ALQADI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2005</xocs:ref-pub-year>
            <xocs:ref-first-fp>763</xocs:ref-first-fp>
            <xocs:ref-last-lp>772</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>I</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0080">
            <xocs:ref-normalized-surname>PLATI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2013</xocs:ref-pub-year>
            <xocs:ref-first-fp>3</xocs:ref-first-fp>
            <xocs:ref-last-lp>10</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>C</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0085">
            <xocs:ref-normalized-surname>MUNAWAR</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-article-number>103916</xocs:ref-article-number>
            <xocs:ref-normalized-initial>H</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0090">
            <xocs:ref-normalized-surname>FAGRHI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2015</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>A</xocs:ref-normalized-initial>
            <xocs:ref-normalized-srctitle>SATELLITEASSESSMENTMONITORINGFORPAVEMENTMANAGEMENT</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0095">
            <xocs:ref-normalized-surname>OZDEN</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2016</xocs:ref-pub-year>
            <xocs:ref-first-fp>752</xocs:ref-first-fp>
            <xocs:ref-last-lp>759</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>A</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0100">
            <xocs:ref-normalized-surname>SUANPAGA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2010</xocs:ref-pub-year>
            <xocs:ref-first-fp>2531</xocs:ref-first-fp>
            <xocs:ref-last-lp>2546</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>W</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0105">
            <xocs:ref-normalized-surname>KARIMZADEH</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2020</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>S</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0110">
            <xocs:ref-normalized-surname>MEYER</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2019</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>F</xocs:ref-normalized-initial>
            <xocs:ref-normalized-srctitle>SARHANDBCOMPRMETHODOLFORMONITBIOMASSESTIM</xocs:ref-normalized-srctitle>
            <xocs:ref-normalized-article-title>SPACEBORNESYNTHETICAPERTURERADARPRINCIPLESDATAACCESSBASICPROCESSINGTECHNIQUES</xocs:ref-normalized-article-title>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0115">
            <xocs:ref-normalized-surname>JAYBHAY</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2015</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>J</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0120">
            <xocs:ref-normalized-surname>MEYER</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2020</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>F</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0125">
            <xocs:ref-normalized-surname>COPERNICUSSENTINELDATA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2019</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>RETRIEVEDASFDAACPROCESSEDBYESA</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0130">
            <xocs:ref-normalized-surname>CRIMMINS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1985</xocs:ref-pub-year>
            <xocs:ref-first-fp>1438</xocs:ref-first-fp>
            <xocs:ref-last-lp>1443</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>T</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0135">
            <xocs:ref-normalized-surname>PARRILLI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2012</xocs:ref-pub-year>
            <xocs:ref-first-fp>606</xocs:ref-first-fp>
            <xocs:ref-last-lp>616</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>S</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0140">
            <xocs:ref-normalized-surname>OLIVER</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1997</xocs:ref-pub-year>
            <xocs:ref-first-fp>1689</xocs:ref-first-fp>
            <xocs:ref-last-lp>1699</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>C</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0145">
            <xocs:ref-normalized-surname>GUO</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2018</xocs:ref-pub-year>
            <xocs:ref-first-fp>722</xocs:ref-first-fp>
            <xocs:ref-normalized-initial>F</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0150">
            <xocs:ref-normalized-surname>JAMES</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2013</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>G</xocs:ref-normalized-initial>
            <xocs:ref-normalized-srctitle>INTRODUCTIONSTATISTICALLEARNING</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0155">
            <xocs:ref-normalized-surname>BARUA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-first-fp>1673</xocs:ref-first-fp>
            <xocs:ref-last-lp>1687</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>L</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0160">
            <xocs:ref-normalized-surname>CHAKRABORTY</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2020</xocs:ref-pub-year>
            <xocs:ref-article-number>101201</xocs:ref-article-number>
            <xocs:ref-normalized-initial>D</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0165">
            <xocs:ref-normalized-surname>SOLLAZZO</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2017</xocs:ref-pub-year>
            <xocs:ref-first-fp>684</xocs:ref-first-fp>
            <xocs:ref-last-lp>693</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>G</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0170">
            <xocs:ref-normalized-surname>ZEIADA</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2020</xocs:ref-pub-year>
            <xocs:ref-first-fp>4091</xocs:ref-first-fp>
            <xocs:ref-last-lp>4109</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>W</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0175">
            <xocs:ref-normalized-surname>KARGAHOSTADI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2014</xocs:ref-pub-year>
            <xocs:ref-first-fp>1222</xocs:ref-first-fp>
            <xocs:ref-last-lp>1229</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>N</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0180">
            <xocs:ref-normalized-surname>YAMANY</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2020</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>M</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0185">
            <xocs:ref-normalized-surname>ZIARI</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2016</xocs:ref-pub-year>
            <xocs:ref-first-fp>776</xocs:ref-first-fp>
            <xocs:ref-last-lp>788</xocs:ref-last-lp>
            <xocs:ref-normalized-initial>H</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0190">
            <xocs:ref-normalized-surname>MNDOT</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2019</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>PAVEMENTCONDITIONANNUALREPORT2019</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0195">
            <xocs:ref-normalized-surname>SAYERS</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>1995</xocs:ref-pub-year>
            <xocs:ref-normalized-initial>M</xocs:ref-normalized-initial>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0200">
            <xocs:ref-normalized-surname>MICHIGANDEPARTMENTOFTRANSPORTATION</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2017</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>ASSETMANAGEMENTBACKGROUNDINTERNATIONALROUGHNESSINDEXIRI</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0205">
            <xocs:ref-normalized-surname>MNDOT</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2011</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>MNDOTPAVEMENTDISTRESSIDENTIFICATIONMANUAL</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0210">
            <xocs:ref-normalized-surname>ASFDAAC</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2021</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>CONTAINSMODIFIEDCOPERNICUSSENTINELDATAPROCESSEDBYESA</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
         <xocs:ref-info refid="rf0215">
            <xocs:ref-normalized-surname>MNDNR</xocs:ref-normalized-surname>
            <xocs:ref-pub-year>2022</xocs:ref-pub-year>
            <xocs:ref-normalized-srctitle>MINNEAPOLISSTPAULCLIMATEDATASNOWDATARESOURCES</xocs:ref-normalized-srctitle>
         </xocs:ref-info>
      </xocs:references>
      <xocs:refkeys>
         <xocs:refkey3>BASHARX2022X104504</xocs:refkey3>
         <xocs:refkey4ai>BASHARX2022X104504XM</xocs:refkey4ai>
      </xocs:refkeys>
      <xocs:open-access>
         <xocs:oa-article-status is-open-access="0" is-open-archive="0"/>
      </xocs:open-access>
      <xocs:open-research>
         <xocs:or-embargo-opening-date>2024-08-03T00:00:00.000Z</xocs:or-embargo-opening-date>
      </xocs:open-research>
      <xocs:self-archiving>
         <xocs:sa-start-date>2024-08-03T00:00:00.000Z</xocs:sa-start-date>
         <xocs:sa-user-license>http://creativecommons.org/licenses/by-nc-nd/4.0/</xocs:sa-user-license>
      </xocs:self-archiving>
      <xocs:copyright-info>
         <xocs:cp-notices>
            <xocs:cp-notice lang="en">© 2022 Elsevier B.V. All rights reserved.</xocs:cp-notice>
         </xocs:cp-notices>
      </xocs:copyright-info>
      <xocs:funding-list has-funding-info="1">
         <xocs:funding-addon-generated-timestamp>2022-08-10T01:08:07.071Z</xocs:funding-addon-generated-timestamp>
         <xocs:funding-addon-type>http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined</xocs:funding-addon-type>
      </xocs:funding-list>
      <xocs:article-sharing-framework>
         <xocs:asf-license>https://doi.org/10.15223/policy-017</xocs:asf-license>
         <xocs:asf-license>https://doi.org/10.15223/policy-037</xocs:asf-license>
         <xocs:asf-license>https://doi.org/10.15223/policy-012</xocs:asf-license>
         <xocs:asf-license>https://doi.org/10.15223/policy-029</xocs:asf-license>
         <xocs:asf-license>https://doi.org/10.15223/policy-004</xocs:asf-license>
      </xocs:article-sharing-framework>
      <xocs:attachment-metadata-doc>
         <xocs:attachment-set-type>item</xocs:attachment-set-type>
         <xocs:pii-formatted>S0926-5805(22)00377-6</xocs:pii-formatted>
         <xocs:pii-unformatted>S0926580522003776</xocs:pii-unformatted>
         <xocs:eid>1-s2.0-S0926580522003776</xocs:eid>
         <xocs:doi>10.1016/j.autcon.2022.104504</xocs:doi>
         <xocs:cid>271427</xocs:cid>
         <xocs:timestamp>2023-08-17T22:21:12.883703Z</xocs:timestamp>
         <xocs:cover-date-start>2022-10-01</xocs:cover-date-start>
         <xocs:cover-date-end>2022-10-31</xocs:cover-date-end>
         <xocs:attachments>
            <xocs:web-pdf>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-main.pdf</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/MAIN/application/pdf/8f157fc3172994af9ddfa9cd3c8729e8/main.pdf</xocs:ucs-locator>
               <xocs:filename>main.pdf</xocs:filename>
               <xocs:extension>pdf</xocs:extension>
               <xocs:pdf-optimized>true</xocs:pdf-optimized>
               <xocs:filesize>4807097</xocs:filesize>
               <xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose>
               <xocs:web-pdf-page-count>12</xocs:web-pdf-page-count>
               <xocs:web-pdf-images>
                  <xocs:web-pdf-image>
                     <xocs:attachment-eid>1-s2.0-S0926580522003776-main_1.png</xocs:attachment-eid>
                     <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/PREVIEW/image/png/1414d2e218b39330a5945b7bed22179f/main_1.png</xocs:ucs-locator>
                     <xocs:filename>main_1.png</xocs:filename>
                     <xocs:extension>png</xocs:extension>
                     <xocs:filesize>57929</xocs:filesize>
                     <xocs:pixel-height>849</xocs:pixel-height>
                     <xocs:pixel-width>656</xocs:pixel-width>
                     <xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type>
                     <xocs:pdf-page-num>1</xocs:pdf-page-num>
                  </xocs:web-pdf-image>
               </xocs:web-pdf-images>
            </xocs:web-pdf>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr15.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr15/DOWNSAMPLED/image/jpeg/8c37e021cf420fb0dbdc6d6a134bfb7a/gr15.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr15</xocs:file-basename>
               <xocs:filename>gr15.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>36348</xocs:filesize>
               <xocs:pixel-height>300</xocs:pixel-height>
               <xocs:pixel-width>587</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr16.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr16/DOWNSAMPLED/image/jpeg/553a4044383e97d52c1d4d08ddf27b6a/gr16.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr16</xocs:file-basename>
               <xocs:filename>gr16.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>26832</xocs:filesize>
               <xocs:pixel-height>250</xocs:pixel-height>
               <xocs:pixel-width>355</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr13.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr13/DOWNSAMPLED/image/jpeg/0917074dbe90c6ce7300b56a4f644d52/gr13.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr13</xocs:file-basename>
               <xocs:filename>gr13.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>52990</xocs:filesize>
               <xocs:pixel-height>297</xocs:pixel-height>
               <xocs:pixel-width>587</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr14.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr14/DOWNSAMPLED/image/jpeg/a59ea363cd3350638b7c972d74acf37e/gr14.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr14</xocs:file-basename>
               <xocs:filename>gr14.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>39818</xocs:filesize>
               <xocs:pixel-height>293</xocs:pixel-height>
               <xocs:pixel-width>587</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr11.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr11/DOWNSAMPLED/image/jpeg/bed7fbd5de0d6408d2af8b460307a402/gr11.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr11</xocs:file-basename>
               <xocs:filename>gr11.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>24153</xocs:filesize>
               <xocs:pixel-height>228</xocs:pixel-height>
               <xocs:pixel-width>498</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr12.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr12/DOWNSAMPLED/image/jpeg/f8098a5d30783298df146cd2c3b25188/gr12.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr12</xocs:file-basename>
               <xocs:filename>gr12.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>18078</xocs:filesize>
               <xocs:pixel-height>184</xocs:pixel-height>
               <xocs:pixel-width>389</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr10.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr10/DOWNSAMPLED/image/jpeg/90d418fe9322af078b11ff29dec600fe/gr10.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr10</xocs:file-basename>
               <xocs:filename>gr10.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>77555</xocs:filesize>
               <xocs:pixel-height>258</xocs:pixel-height>
               <xocs:pixel-width>533</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr1.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr1/DOWNSAMPLED/image/jpeg/bc0ab37cd68db37053b92e91d15301d5/gr1.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr1</xocs:file-basename>
               <xocs:filename>gr1.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>18598</xocs:filesize>
               <xocs:pixel-height>193</xocs:pixel-height>
               <xocs:pixel-width>538</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr17.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr17/DOWNSAMPLED/image/jpeg/1cb338c2052e3f32aa2992d7719c522f/gr17.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr17</xocs:file-basename>
               <xocs:filename>gr17.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>15603</xocs:filesize>
               <xocs:pixel-height>252</xocs:pixel-height>
               <xocs:pixel-width>355</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr18.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr18/DOWNSAMPLED/image/jpeg/a61827a63cab24cb4ef2610596872a83/gr18.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr18</xocs:file-basename>
               <xocs:filename>gr18.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>24354</xocs:filesize>
               <xocs:pixel-height>325</xocs:pixel-height>
               <xocs:pixel-width>320</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr9.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr9/DOWNSAMPLED/image/jpeg/ae77e1b16fbac6f4ef12e64066af460a/gr9.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr9</xocs:file-basename>
               <xocs:filename>gr9.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>60673</xocs:filesize>
               <xocs:pixel-height>370</xocs:pixel-height>
               <xocs:pixel-width>389</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr8.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr8/DOWNSAMPLED/image/jpeg/1b15fee445088026cfb7309ce131d252/gr8.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr8</xocs:file-basename>
               <xocs:filename>gr8.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>23139</xocs:filesize>
               <xocs:pixel-height>193</xocs:pixel-height>
               <xocs:pixel-width>533</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr7.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr7/DOWNSAMPLED/image/jpeg/77c0ff328ea873e0791215170f693d13/gr7.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr7</xocs:file-basename>
               <xocs:filename>gr7.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>26434</xocs:filesize>
               <xocs:pixel-height>274</xocs:pixel-height>
               <xocs:pixel-width>498</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr6.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr6/DOWNSAMPLED/image/jpeg/765231db933dad3b0b6fc50aa92134c2/gr6.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr6</xocs:file-basename>
               <xocs:filename>gr6.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>23320</xocs:filesize>
               <xocs:pixel-height>250</xocs:pixel-height>
               <xocs:pixel-width>533</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr5.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr5/DOWNSAMPLED/image/jpeg/dfedbfc5ec4398b5fadabe920d9480dc/gr5.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr5</xocs:file-basename>
               <xocs:filename>gr5.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>28682</xocs:filesize>
               <xocs:pixel-height>179</xocs:pixel-height>
               <xocs:pixel-width>389</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr4.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr4/DOWNSAMPLED/image/jpeg/1135bc662ed70e65e03cbe8d2ee344a6/gr4.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr4</xocs:file-basename>
               <xocs:filename>gr4.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>13105</xocs:filesize>
               <xocs:pixel-height>83</xocs:pixel-height>
               <xocs:pixel-width>498</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr3.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr3/DOWNSAMPLED/image/jpeg/15e24d40a870f6bcd6e82925979468cb/gr3.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr3</xocs:file-basename>
               <xocs:filename>gr3.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>131965</xocs:filesize>
               <xocs:pixel-height>445</xocs:pixel-height>
               <xocs:pixel-width>711</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr2.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr2/DOWNSAMPLED/image/jpeg/97c8cf47244a71a2301c6645159d62c3/gr2.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr2</xocs:file-basename>
               <xocs:filename>gr2.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>11587</xocs:filesize>
               <xocs:pixel-height>170</xocs:pixel-height>
               <xocs:pixel-width>498</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr15.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr15/THUMBNAIL/image/gif/eef4ff06f4cae66e529f7dca41badbda/gr15.sml</xocs:ucs-locator>
               <xocs:file-basename>gr15</xocs:file-basename>
               <xocs:filename>gr15.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>6217</xocs:filesize>
               <xocs:pixel-height>112</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr16.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr16/THUMBNAIL/image/gif/237795333bf6d355368acc3499a8b505/gr16.sml</xocs:ucs-locator>
               <xocs:file-basename>gr16</xocs:file-basename>
               <xocs:filename>gr16.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>7936</xocs:filesize>
               <xocs:pixel-height>154</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr13.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr13/THUMBNAIL/image/gif/bc291f52da103293dabfad6dba6d4f4e/gr13.sml</xocs:ucs-locator>
               <xocs:file-basename>gr13</xocs:file-basename>
               <xocs:filename>gr13.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>7347</xocs:filesize>
               <xocs:pixel-height>111</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr14.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr14/THUMBNAIL/image/gif/3f3462ff63075bbae06989fb843ef335/gr14.sml</xocs:ucs-locator>
               <xocs:file-basename>gr14</xocs:file-basename>
               <xocs:filename>gr14.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>5718</xocs:filesize>
               <xocs:pixel-height>109</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr11.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr11/THUMBNAIL/image/gif/ae88bfe4cfa05c964ba55ccd3fe08d54/gr11.sml</xocs:ucs-locator>
               <xocs:file-basename>gr11</xocs:file-basename>
               <xocs:filename>gr11.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>4377</xocs:filesize>
               <xocs:pixel-height>100</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr12.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr12/THUMBNAIL/image/gif/34c2a49cae309001452589acc10642f4/gr12.sml</xocs:ucs-locator>
               <xocs:file-basename>gr12</xocs:file-basename>
               <xocs:filename>gr12.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>9245</xocs:filesize>
               <xocs:pixel-height>103</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr10.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr10/THUMBNAIL/image/gif/e5e9ccaeb14a0eb95284c8636c0fba01/gr10.sml</xocs:ucs-locator>
               <xocs:file-basename>gr10</xocs:file-basename>
               <xocs:filename>gr10.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>18010</xocs:filesize>
               <xocs:pixel-height>106</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr1.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr1/THUMBNAIL/image/gif/d6c1e2ea8e849d55cccde5c04dcf8943/gr1.sml</xocs:ucs-locator>
               <xocs:file-basename>gr1</xocs:file-basename>
               <xocs:filename>gr1.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>2634</xocs:filesize>
               <xocs:pixel-height>78</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr17.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr17/THUMBNAIL/image/gif/cbed6bb53f67b9aa6ba24965673f168e/gr17.sml</xocs:ucs-locator>
               <xocs:file-basename>gr17</xocs:file-basename>
               <xocs:filename>gr17.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>5684</xocs:filesize>
               <xocs:pixel-height>155</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr18.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr18/THUMBNAIL/image/gif/4a7330cbe0ceef6d1a3825dad69a5609/gr18.sml</xocs:ucs-locator>
               <xocs:file-basename>gr18</xocs:file-basename>
               <xocs:filename>gr18.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>11091</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>161</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr9.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr9/THUMBNAIL/image/gif/1cd1586a9451555815b3d50e6ae62a5c/gr9.sml</xocs:ucs-locator>
               <xocs:file-basename>gr9</xocs:file-basename>
               <xocs:filename>gr9.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>21382</xocs:filesize>
               <xocs:pixel-height>164</xocs:pixel-height>
               <xocs:pixel-width>172</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr8.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr8/THUMBNAIL/image/gif/59576f7262d75404848b11998b360b6b/gr8.sml</xocs:ucs-locator>
               <xocs:file-basename>gr8</xocs:file-basename>
               <xocs:filename>gr8.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>4414</xocs:filesize>
               <xocs:pixel-height>79</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr7.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr7/THUMBNAIL/image/gif/9ec03ae7928eba1102534ac2ffbed528/gr7.sml</xocs:ucs-locator>
               <xocs:file-basename>gr7</xocs:file-basename>
               <xocs:filename>gr7.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>4526</xocs:filesize>
               <xocs:pixel-height>121</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr6.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr6/THUMBNAIL/image/gif/57c3d05956c471877acd9dc4f8c0d62e/gr6.sml</xocs:ucs-locator>
               <xocs:file-basename>gr6</xocs:file-basename>
               <xocs:filename>gr6.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>3583</xocs:filesize>
               <xocs:pixel-height>103</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr5.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr5/THUMBNAIL/image/gif/d0ae6af0fd00285d123bb8e4fab4184f/gr5.sml</xocs:ucs-locator>
               <xocs:file-basename>gr5</xocs:file-basename>
               <xocs:filename>gr5.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>16673</xocs:filesize>
               <xocs:pixel-height>101</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr4.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr4/THUMBNAIL/image/gif/3f6f87b2df3cc87edec63c814aef09c0/gr4.sml</xocs:ucs-locator>
               <xocs:file-basename>gr4</xocs:file-basename>
               <xocs:filename>gr4.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>5943</xocs:filesize>
               <xocs:pixel-height>37</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr3.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr3/THUMBNAIL/image/gif/9588bc88b4f491c95026cee7df9c5d0a/gr3.sml</xocs:ucs-locator>
               <xocs:file-basename>gr3</xocs:file-basename>
               <xocs:filename>gr3.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>11065</xocs:filesize>
               <xocs:pixel-height>137</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr2.sml</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr2/THUMBNAIL/image/gif/f6eb85bf68d4d91ddc8301733e888997/gr2.sml</xocs:ucs-locator>
               <xocs:file-basename>gr2</xocs:file-basename>
               <xocs:filename>gr2.sml</xocs:filename>
               <xocs:extension>sml</xocs:extension>
               <xocs:filesize>3019</xocs:filesize>
               <xocs:pixel-height>75</xocs:pixel-height>
               <xocs:pixel-width>219</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr15_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr15/HIGHRES/image/jpeg/2a4c6f597f584e2c37e7fb747425b822/gr15_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr15</xocs:file-basename>
               <xocs:filename>gr15_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>120507</xocs:filesize>
               <xocs:pixel-height>796</xocs:pixel-height>
               <xocs:pixel-width>1559</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr16_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr16/HIGHRES/image/jpeg/0d19ff1432f0c2322078f7ab1287c534/gr16_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr16</xocs:file-basename>
               <xocs:filename>gr16_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>99376</xocs:filesize>
               <xocs:pixel-height>666</xocs:pixel-height>
               <xocs:pixel-width>945</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr13_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr13/HIGHRES/image/jpeg/2bc481a9ebaa5c0bf66bef97bd67d698/gr13_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr13</xocs:file-basename>
               <xocs:filename>gr13_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>177374</xocs:filesize>
               <xocs:pixel-height>789</xocs:pixel-height>
               <xocs:pixel-width>1559</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr14_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr14/HIGHRES/image/jpeg/eb6f7880dae01ae7c1d8f3efb7a2f4d1/gr14_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr14</xocs:file-basename>
               <xocs:filename>gr14_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>137888</xocs:filesize>
               <xocs:pixel-height>778</xocs:pixel-height>
               <xocs:pixel-width>1559</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr11_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr11/HIGHRES/image/jpeg/7fa8b7db480fa2b3fdc83b1e1a359f60/gr11_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr11</xocs:file-basename>
               <xocs:filename>gr11_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>74130</xocs:filesize>
               <xocs:pixel-height>606</xocs:pixel-height>
               <xocs:pixel-width>1323</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr12_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr12/HIGHRES/image/jpeg/f22b61381667a145cc17b3eeeb14ce78/gr12_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr12</xocs:file-basename>
               <xocs:filename>gr12_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>145868</xocs:filesize>
               <xocs:pixel-height>813</xocs:pixel-height>
               <xocs:pixel-width>1722</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr10_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr10/HIGHRES/image/jpeg/03b3134f79dbfb6e23d1dcdfc628113c/gr10_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr10</xocs:file-basename>
               <xocs:filename>gr10_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>515095</xocs:filesize>
               <xocs:pixel-height>685</xocs:pixel-height>
               <xocs:pixel-width>1417</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr1_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr1/HIGHRES/image/jpeg/885a0c165cde83c2ebd1ddeedd10185f/gr1_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr1</xocs:file-basename>
               <xocs:filename>gr1_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>148729</xocs:filesize>
               <xocs:pixel-height>854</xocs:pixel-height>
               <xocs:pixel-width>2384</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr17_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr17/HIGHRES/image/jpeg/243b0b29f00083f56fadd5ae39770423/gr17_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr17</xocs:file-basename>
               <xocs:filename>gr17_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>53329</xocs:filesize>
               <xocs:pixel-height>670</xocs:pixel-height>
               <xocs:pixel-width>945</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr18_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr18/HIGHRES/image/jpeg/99be33a1a3a6ce2021bbfcbdf877a5b5/gr18_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr18</xocs:file-basename>
               <xocs:filename>gr18_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>86995</xocs:filesize>
               <xocs:pixel-height>864</xocs:pixel-height>
               <xocs:pixel-width>850</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr9_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr9/HIGHRES/image/jpeg/3f3ba34853a006223c380a34b5480ca8/gr9_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr9</xocs:file-basename>
               <xocs:filename>gr9_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>288818</xocs:filesize>
               <xocs:pixel-height>982</xocs:pixel-height>
               <xocs:pixel-width>1033</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr8_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr8/HIGHRES/image/jpeg/73ef712d7ed371eb0967c798fc254cf8/gr8_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr8</xocs:file-basename>
               <xocs:filename>gr8_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>72391</xocs:filesize>
               <xocs:pixel-height>512</xocs:pixel-height>
               <xocs:pixel-width>1417</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr7_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr7/HIGHRES/image/jpeg/48221d86cc2e0b85c7a1b2d1e5a12420/gr7_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr7</xocs:file-basename>
               <xocs:filename>gr7_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>163299</xocs:filesize>
               <xocs:pixel-height>1215</xocs:pixel-height>
               <xocs:pixel-width>2205</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr6_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr6/HIGHRES/image/jpeg/01264d2931d2b5ce08eaa1aeb5516291/gr6_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr6</xocs:file-basename>
               <xocs:filename>gr6_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>151186</xocs:filesize>
               <xocs:pixel-height>1108</xocs:pixel-height>
               <xocs:pixel-width>2362</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr5_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr5/HIGHRES/image/jpeg/7e9e76d94fcbed054706ce86a3dad7a9/gr5_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr5</xocs:file-basename>
               <xocs:filename>gr5_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>525015</xocs:filesize>
               <xocs:pixel-height>792</xocs:pixel-height>
               <xocs:pixel-width>1722</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr4_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr4/HIGHRES/image/jpeg/cea9f1e3a19f735b9fa19f4c8da223fd/gr4_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr4</xocs:file-basename>
               <xocs:filename>gr4_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>108054</xocs:filesize>
               <xocs:pixel-height>369</xocs:pixel-height>
               <xocs:pixel-width>2205</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr3_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr3/HIGHRES/image/jpeg/69ea4ebf456af04f7fdde2a988a751b0/gr3_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr3</xocs:file-basename>
               <xocs:filename>gr3_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>453944</xocs:filesize>
               <xocs:pixel-height>1183</xocs:pixel-height>
               <xocs:pixel-width>1890</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-gr2_lrg.jpg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/gr2/HIGHRES/image/jpeg/f7d8316f3083d38c1837084980c22534/gr2_lrg.jpg</xocs:ucs-locator>
               <xocs:file-basename>gr2</xocs:file-basename>
               <xocs:filename>gr2_lrg.jpg</xocs:filename>
               <xocs:extension>jpg</xocs:extension>
               <xocs:filesize>95517</xocs:filesize>
               <xocs:pixel-height>751</xocs:pixel-height>
               <xocs:pixel-width>2205</xocs:pixel-width>
               <xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si1.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/595062b9dc1dc8273803980d589f011a/si1.svg</xocs:ucs-locator>
               <xocs:file-basename>si1</xocs:file-basename>
               <xocs:filename>si1.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>4315</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si2.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/8463f7f762358ccdb04b32163d4fb516/si2.svg</xocs:ucs-locator>
               <xocs:file-basename>si2</xocs:file-basename>
               <xocs:filename>si2.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>5996</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si3.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/b6879165145dc08ef1c9e6a259548b26/si3.svg</xocs:ucs-locator>
               <xocs:file-basename>si3</xocs:file-basename>
               <xocs:filename>si3.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>10907</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si4.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/3c2667d9a459f6cd3472432aed73efb3/si4.svg</xocs:ucs-locator>
               <xocs:file-basename>si4</xocs:file-basename>
               <xocs:filename>si4.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>10878</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si5.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/784fab01cd7ffb1c032eb019d6567fe3/si5.svg</xocs:ucs-locator>
               <xocs:file-basename>si5</xocs:file-basename>
               <xocs:filename>si5.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>9683</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si6.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/8f5b641af15750eabf01660b29e2eb86/si6.svg</xocs:ucs-locator>
               <xocs:file-basename>si6</xocs:file-basename>
               <xocs:filename>si6.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>11786</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si7.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/43c52ac6a811ccc3f3df740f38d451a3/si7.svg</xocs:ucs-locator>
               <xocs:file-basename>si7</xocs:file-basename>
               <xocs:filename>si7.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>12894</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-si8.svg</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0926580522003776/STRIPIN/image/svg+xml/5d15f16cf509a49f8dbda97e03a48d8f/si8.svg</xocs:ucs-locator>
               <xocs:file-basename>si8</xocs:file-basename>
               <xocs:filename>si8.svg</xocs:filename>
               <xocs:extension>svg</xocs:extension>
               <xocs:filesize>11483</xocs:filesize>
               <xocs:attachment-type>ALTIMG</xocs:attachment-type>
            </xocs:attachment>
            <xocs:attachment>
               <xocs:attachment-eid>1-s2.0-S0926580522003776-am.pdf</xocs:attachment-eid>
               <xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10LXLB60TWF/MAIN/application/pdf/c2afe389b60f5e1010a74a2998b0ceb5/am.pdf</xocs:ucs-locator>
               <xocs:file-basename>am</xocs:file-basename>
               <xocs:filename>am.pdf</xocs:filename>
               <xocs:extension>pdf</xocs:extension>
               <xocs:pdf-optimized>false</xocs:pdf-optimized>
               <xocs:filesize>2725098</xocs:filesize>
               <xocs:attachment-type>AAM-PDF</xocs:attachment-type>
            </xocs:attachment>
         </xocs:attachments>
      </xocs:attachment-metadata-doc>
   </xocs:meta><xocs:serial-item xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd">
      <article xmlns="http://www.elsevier.com/xml/ja/dtd" version="5.6" docsubtype="fla" xml:lang="en">
         <item-info>
            <jid>AUTCON</jid>
            <aid>104504</aid>
            <ce:article-number>104504</ce:article-number>
            <ce:pii>S0926-5805(22)00377-6</ce:pii>
            <ce:doi>10.1016/j.autcon.2022.104504</ce:doi>
            <ce:copyright type="full-transfer" year="2022">Elsevier B.V.</ce:copyright>
         </item-info>
         <ce:floats>
            <ce:figure id="f0005">
               <ce:label>Fig. 1</ce:label>
               <ce:caption id="ca0005">
                  <ce:simple-para id="sp0005" view="all">SAR backscatters depend on the surface roughness. (a) Smooth surfaces will have lower backscattering coefficients than (b) intermediate, and (c) rough surfaces. Image adapted from [<ce:cross-ref id="cf0005" refid="bb0110">22</ce:cross-ref>].</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0005">Fig. 1</ce:alt-text>
               <ce:link id="lk0005" locator="gr1" xlink:type="simple" xlink:href="pii:S0926580522003776/gr1" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0010">
               <ce:label>Fig. 2</ce:label>
               <ce:caption id="ca0010">
                  <ce:simple-para id="sp0010" view="all">SAR backscattering in the (a) presence, and (b) absence of traffic. Image adapted from [<ce:cross-ref id="cf0010" refid="bb0105">21</ce:cross-ref>].</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0010">Fig. 2</ce:alt-text>
               <ce:link id="lk0010" locator="gr2" xlink:type="simple" xlink:href="pii:S0926580522003776/gr2" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0015">
               <ce:label>Fig. 3</ce:label>
               <ce:caption id="ca0015">
                  <ce:simple-para id="sp0015" view="all">Proposed framework to estimate pavement condition using SAR imagery.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0015">Fig. 3</ce:alt-text>
               <ce:link id="lk0015" locator="gr3" xlink:type="simple" xlink:href="pii:S0926580522003776/gr3" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0020">
               <ce:label>Fig. 4</ce:label>
               <ce:caption id="ca0020">
                  <ce:simple-para id="sp0020" view="all">Road reference points overlaid on top of (a) satellite, and (b) processed SAR image.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0020">Fig. 4</ce:alt-text>
               <ce:link id="lk0020" locator="gr4" xlink:type="simple" xlink:href="pii:S0926580522003776/gr4" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0025">
               <ce:label>Fig. 5</ce:label>
               <ce:caption id="ca0025">
                  <ce:simple-para id="sp0025" view="all">US-169 pavement surface showing locations with (a) low, and (b) high IRI values.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0025">Fig. 5</ce:alt-text>
               <ce:link id="lk0025" locator="gr5" xlink:type="simple" xlink:href="pii:S0926580522003776/gr5" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0030">
               <ce:label>Fig. 6</ce:label>
               <ce:caption id="ca0030">
                  <ce:simple-para id="sp0030" view="all">Distribution of (a) IRI, and (b) <ce:italic>γ</ce:italic>
                     <ce:inf loc="post">0</ce:inf> values in the final dataset.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0030">Fig. 6</ce:alt-text>
               <ce:link id="lk0030" locator="gr6" xlink:type="simple" xlink:href="pii:S0926580522003776/gr6" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0035">
               <ce:label>Fig. 7</ce:label>
               <ce:caption id="ca0035">
                  <ce:simple-para id="sp0035" view="all">Backscatters in (a) VV, and (b) VH polarization for pavements in different condition.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0035">Fig. 7</ce:alt-text>
               <ce:link id="lk0035" locator="gr7" xlink:type="simple" xlink:href="pii:S0926580522003776/gr7" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0040">
               <ce:label>Fig. 8</ce:label>
               <ce:caption id="ca0040">
                  <ce:simple-para id="sp0040" view="all">Performance of filters in suppressing speckles in pavement pixels.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0040">Fig. 8</ce:alt-text>
               <ce:link id="lk0040" locator="gr8" xlink:type="simple" xlink:href="pii:S0926580522003776/gr8" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0045">
               <ce:label>Fig. 9</ce:label>
               <ce:caption id="ca0045">
                  <ce:simple-para id="sp0045" view="all">(a) Original image as compared to (b) IDAN, (c) Lee, (d) Refined Lee filtered image.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0045">Fig. 9</ce:alt-text>
               <ce:link id="lk0045" locator="gr9" xlink:type="simple" xlink:href="pii:S0926580522003776/gr9" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0050">
               <ce:label>Fig. 10</ce:label>
               <ce:caption id="ca0050">
                  <ce:simple-para id="sp0050" view="all">Processed SAR image (a) without, and (b) with radiometric terrain correction.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0050">Fig. 10</ce:alt-text>
               <ce:link id="lk0050" locator="gr10" xlink:type="simple" xlink:href="pii:S0926580522003776/gr10" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0055">
               <ce:label>Fig. 11</ce:label>
               <ce:caption id="ca0055">
                  <ce:simple-para id="sp0055" view="all">Seasonal variations in VV backscatter values from pavements over the study period.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0055">Fig. 11</ce:alt-text>
               <ce:link id="lk0055" locator="gr11" xlink:type="simple" xlink:href="pii:S0926580522003776/gr11" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0060">
               <ce:label>Fig. 12</ce:label>
               <ce:caption id="ca0060">
                  <ce:simple-para id="sp0060" view="all">(a) Satellite image, (b) an individual SAR image, and (c) the minimum intensity projection image generated from a stack.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0060">Fig. 12</ce:alt-text>
               <ce:link id="lk0060" locator="gr12" xlink:type="simple" xlink:href="pii:S0926580522003776/gr12" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0065">
               <ce:label>Fig. 13</ce:label>
               <ce:caption id="ca0065">
                  <ce:simple-para id="sp0065" view="all">Performance of the model during (a) training, and (b) testing.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0065">Fig. 13</ce:alt-text>
               <ce:link id="lk0065" locator="gr13" xlink:type="simple" xlink:href="pii:S0926580522003776/gr13" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0070">
               <ce:label>Fig. 14</ce:label>
               <ce:caption id="ca0070">
                  <ce:simple-para id="sp0070" view="all">(a) Residual plot, and (b) normal Q-Q plot showing the distribution of residuals.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0070">Fig. 14</ce:alt-text>
               <ce:link id="lk0070" locator="gr14" xlink:type="simple" xlink:href="pii:S0926580522003776/gr14" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0075">
               <ce:label>Fig. 15</ce:label>
               <ce:caption id="ca0075">
                  <ce:simple-para id="sp0075" view="all">Performance of (a) simple linear regression model based on <ce:italic>γ</ce:italic>
                     <ce:inf loc="post">0</ce:inf>, and (b) multiple linear regression based on all the features.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0075">Fig. 15</ce:alt-text>
               <ce:link id="lk0075" locator="gr15" xlink:type="simple" xlink:href="pii:S0926580522003776/gr15" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0080">
               <ce:label>Fig. 16</ce:label>
               <ce:caption id="ca0080">
                  <ce:simple-para id="sp0080" view="all">Prediction intervals associated with point estimations in comparison to actual IRI values.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0080">Fig. 16</ce:alt-text>
               <ce:link id="lk0080" locator="gr16" xlink:type="simple" xlink:href="pii:S0926580522003776/gr16" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0085">
               <ce:label>Fig. 17</ce:label>
               <ce:caption id="ca0085">
                  <ce:simple-para id="sp0085" view="all">Classification accuracy of the model for different RQI classes.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0085">Fig. 17</ce:alt-text>
               <ce:link id="lk0085" locator="gr17" xlink:type="simple" xlink:href="pii:S0926580522003776/gr17" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:figure id="f0090">
               <ce:label>Fig. 18</ce:label>
               <ce:caption id="ca0090">
                  <ce:simple-para id="sp0090" view="all">SAR-C user interface.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0090">Fig. 18</ce:alt-text>
               <ce:link id="lk0090" locator="gr18" xlink:type="simple" xlink:href="pii:S0926580522003776/gr18" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4"/>
            </ce:figure>
            <ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="t0005" frame="topbot" rowsep="0" colsep="0">
               <ce:label>Table 1</ce:label>
               <ce:caption id="ca0095">
                  <ce:simple-para id="sp0095" view="all">RQI performance categories.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0095">Table 1</ce:alt-text>
               <tgroup cols="2">
                  <colspec colname="col1"/>
                  <colspec colname="col2"/>
                  <thead>
                     <row rowsep="1" valign="top">
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">RQI Range</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Performance Measure Category</entry>
                     </row>
                  </thead>
                  <tbody>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">4.1 − 5.0</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Very Good</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">3.1 − 4.0</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Good</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">2.1 − 3.0</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Fair</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">1.1 − 2.0</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Poor</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">0 − 1.0</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Very Poor</entry>
                     </row>
                  </tbody>
               </tgroup>
            </ce:table>
            <ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="t0010" frame="topbot" rowsep="0" colsep="0">
               <ce:label>Table 2</ce:label>
               <ce:caption id="ca0100">
                  <ce:simple-para id="sp0100" view="all">Description of the acquired SAR data.</ce:simple-para>
               </ce:caption>
               <ce:alt-text role="short" id="al0100">Table 2</ce:alt-text>
               <tgroup cols="2">
                  <colspec colname="col1"/>
                  <colspec colname="col2"/>
                  <thead>
                     <row rowsep="1" valign="top">
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Item</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Description</entry>
                     </row>
                  </thead>
                  <tbody>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Sensor</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Sentinel-1A</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Band</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">C</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Wavelength</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">5.6<italic>cm</italic>
                        </entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Spatial Resolution</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">10<italic>m</italic> × 10<italic>m</italic>
                        </entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Revisit Frequency</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">12 days</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Path</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">165</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Frame</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">144</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Acquisition Mode</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Interferometric Wide (IW) swath</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Flight Direction</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Ascending</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Polarization</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">VV + VH</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Level of Preprocessing</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">L1 Ground Range Detected High Resolution</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Number of Images Collected</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">91</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Period Covered</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">Jan 2017 – Dec 2019</entry>
                     </row>
                     <row>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col1">Time of acquisition</entry>
                        <entry xmlns="http://www.elsevier.com/xml/common/dtd" colname="col2">00:05</entry>
                     </row>
                  </tbody>
               </tgroup>
            </ce:table>
         </ce:floats>
         <head>
            <ce:title id="ti0005">Deep learning for estimating pavement roughness using synthetic aperture radar data</ce:title>
            <ce:author-group id="ag0005">
               <ce:author id="au0005" author-id="S0926580522003776-c34b6a1debf16b1c4006c242db086cea">
                  <ce:given-name>Mohammad Z.</ce:given-name>
                  <ce:surname>Bashar</ce:surname>
                  
               </ce:author>
               <ce:author id="au0010" author-id="S0926580522003776-23ee0c7299c2de093c89d04918c5c2ad">
                  <ce:given-name>Cristina</ce:given-name>
                  <ce:surname>Torres-Machi</ce:surname>
                  <ce:cross-ref refid="cr0005" id="cf0015">
                     <ce:sup loc="post">⁎</ce:sup>
                  </ce:cross-ref>
                  
               </ce:author>
               <ce:affiliation id="af0005" affiliation-id="S0926580522003776-7331c282a8639000f828c697c5d35d19">
                  <ce:textfn id="tn0005">Department of Civil, Environmental, and Architectural Engineering, University of Colorado Boulder, 1111 Engineering Drive, Boulder, CO 80309-0428, United States of America</ce:textfn>
                  <sa:affiliation>
                     <sa:organization>Department of Civil, Environmental, and Architectural Engineering</sa:organization>
                     <sa:organization>University of Colorado Boulder</sa:organization>
                     <sa:address-line>1111 Engineering Drive</sa:address-line>
                     <sa:city>Boulder</sa:city>
                     <sa:state>CO</sa:state>
                     <sa:postal-code>80309-0428</sa:postal-code>
                     <sa:country>United States of America</sa:country>
                  </sa:affiliation>
                  <ce:source-text id="se0005">Graduate Research Assistant, Department of Civil, Environmental, and Architectural Engineering, University of Colorado Boulder, 1111 Engineering Drive, Boulder, CO 80309-0428</ce:source-text>
               </ce:affiliation>
               <ce:correspondence id="cr0005">
                  <ce:label>⁎</ce:label>
                  <ce:text id="tx0005">Corresponding author.</ce:text>
               </ce:correspondence>
            </ce:author-group>
            <ce:date-received day="5" month="4" year="2022"/>
            <ce:date-revised day="11" month="7" year="2022"/>
            <ce:date-accepted day="26" month="7" year="2022"/>
            <ce:abstract id="ab0005" xml:lang="en" view="all" class="author"><ce:abstract-sec id="as0005" view="all">
                  <ce:simple-para id="sp0105" view="all">Because of the high costs of ground-based pavement condition methods used to monitor pavement condition, transportation agencies often limit distress surveys to their major roads. As a result, the condition of local and ancillary roads remains unknown to decision-makers. This study addresses this gap by exploring the capabilities of publicly available Synthetic Aperture Radar (SAR) data to estimate pavement roughness. This paper introduces a novel framework to address the challenges of using SAR images in evaluating pavement condition. The trunk highway network in Minnesota is analyzed to develop deep learning models that predict International Roughness Index (IRI) and associated prediction intervals. This analysis found that SAR images have a strong potential in quantifying pavement condition. The deep learning models were able to predict IRI with a mean absolute error of 14.6 in./miles and provide intervals of pavement condition that capture actual IRI values with an accuracy of 81%.</ce:simple-para>
               </ce:abstract-sec></ce:abstract>
            
            <ce:keywords id="ks0005" view="all" class="keyword">
               <ce:section-title id="st0015">Keywords</ce:section-title>
               <ce:keyword id="kw0005">
                  <ce:text id="tx0010">Pavement</ce:text>
               </ce:keyword>
               <ce:keyword id="kw0010">
                  <ce:text id="tx0015">IRI</ce:text>
               </ce:keyword>
               <ce:keyword id="kw0015">
                  <ce:text id="tx0020">Deep learning</ce:text>
               </ce:keyword>
               <ce:keyword id="kw0020">
                  <ce:text id="tx0025">Image processing</ce:text>
               </ce:keyword>
               <ce:keyword id="kw0025">
                  <ce:text id="tx0030">Satellite data</ce:text>
               </ce:keyword>
               <ce:keyword id="kw0030">
                  <ce:text id="tx0035">Remote sensing</ce:text>
               </ce:keyword>
            </ce:keywords>
         </head>
         <body view="all">
            <ce:sections>
               <ce:section id="s0005" view="all">
                  <ce:label>1</ce:label>
                  <ce:section-title id="st0020">Introduction</ce:section-title>
                  <ce:para id="p0030" view="all">Accurate and timely assessment of pavement condition is critical in the management of transportation infrastructure, as it determines maintenance needs and funding requirements. The transportation network in the United States comprises 3.9 million miles of built street, roads, and highways: 43% of which are in a poor or mediocre condition [<ce:cross-ref id="cf0020" refid="bb0005">1</ce:cross-ref>,<ce:cross-ref id="cf0025" refid="bb0010">2</ce:cross-ref>]. While users demand more in terms of quality, safety, and accountability, the state Departments of Transportation (DOTs) are faced with challenges of aging pavements, deteriorating networks, and insufficient budgets to inspect and maintain such a large and complex network. Due to the high costs of collecting pavement condition data using ground-based approaches, DOTs often limit their monitoring to the major roads of a network, as required by federal regulations [<ce:cross-ref id="cf0030" refid="bb0015">3</ce:cross-ref>]. As a result, the condition of the ancillary components of a highway system such as ramps, auxiliary lanes, and frontage road pavements remain unknown to decision-makers. This raises the need for alternative solutions to monitor the condition of ancillary roads in a cost-effective manner.</ce:para>
                  <ce:para id="p0035" view="all">Satellite remote sensing has the potential to provide pavement condition information that could complement the ground-based measurements and reduce monitoring costs. Past attempts in extracting road condition from remote sensors have mainly focused on optical satellite imagery [<ce:cross-ref id="cf0035" refid="bb0020">4</ce:cross-ref>,<ce:cross-ref id="cf0040" refid="bb0025">5</ce:cross-ref>]. These approaches, however, are limited by the high cost of very high-resolution images, and the complications associated with processing optical images such as cloud covers, lighting, and weather conditions. Spaceborne Synthetic Aperture Radar (SAR) data effectively addresses these issues. Radar signals can penetrate clouds and image the whole earth during both day and night regardless of the weather condition. Moreover, C-band SAR data from Sentinel-1 satellite are available for public use at zero cost to the user. Previous studies have established SAR imagery to be successful in detecting changes in road surface with millimeter accuracy [<ce:cross-ref id="cf0045" refid="bb0030">6</ce:cross-ref>]. However, no studies so far have explored the potential of this publicly available bigdata in pavement monitoring. Indeed, the traditional computation techniques currently used in modeling pavement condition are ineffective in leveraging big datasets [<ce:cross-ref id="cf0050" refid="bb0035">7</ce:cross-ref>,<ce:cross-ref id="cf0055" refid="bb0040">8</ce:cross-ref>]. With the flourishment of big-data applications, deep learning has emerged as a valuable tool for data-driven decision making in the management of infrastructure assets [<ce:cross-ref id="cf0060" refid="bb0045">9</ce:cross-ref>,<ce:cross-ref id="cf0065" refid="bb0050">10</ce:cross-ref>]. Deep learning algorithms constantly learn patterns from data and are highly effective in progressively extracting higher level features from complex datasets using multiple layers of neurons. In this research, we aim to leverage the capabilities of deep learning algorithms to estimate pavement condition at a network level using state-of-the-art SAR technology.</ce:para>
                  <ce:section id="s0010" view="all">
                     <ce:label>1.1</ce:label>
                     <ce:section-title id="st0025">Objectives</ce:section-title>
                     <ce:para id="p0040" view="all">The primary objective of this study is to establish a framework to estimate pavement roughness using satellite-based SAR data and deep learning algorithms. To accomplish this, we first explored radar signal processing techniques to derive an optimal approach in processing SAR imagery for pavement condition evaluation purposes. Signals extracted from SAR imagery are then combined with relevant pavement features and modeled using deep learning algorithms to estimate pavement condition. The proposed framework was packaged as a software with a graphical user interface to facilitate its implementation by transportation agencies.</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0015" view="all">
                  <ce:label>2</ce:label>
                  <ce:section-title id="st0030">Challenges in using SAR to monitor pavements</ce:section-title>
                  <ce:para id="p0045" view="all">Radar technology, especially Ground Penetrating Radar (GPR), has been widely used for wide variety of pavement applications including modeling pavement deterioration [<ce:cross-ref id="cf0070" refid="bb0055">11</ce:cross-ref>], detecting subsurface cracks [<ce:cross-ref id="cf0075" refid="bb0060">12</ce:cross-ref>,<ce:cross-ref id="cf0080" refid="bb0065">13</ce:cross-ref>], moisture damage [<ce:cross-ref id="cf0085" refid="bb0070">14</ce:cross-ref>], measuring layer thicknesses [<ce:cross-ref id="cf0090" refid="bb0075">15</ce:cross-ref>], and material density [<ce:cross-ref id="cf0095" refid="bb0080">16</ce:cross-ref>]. Despite having a similar working principle, the use of SAR technology in pavement applications, however, is not well established. SAR sensors transmit microwave signals at a slanted angle and measure the backscattered signal to characterize features on earth surface [<ce:cross-ref id="cf0100" refid="bb0085">17</ce:cross-ref>]. Each pixel of the radar image is composed of phase and amplitude information. Phase indicates the distance between the sensor and the reflecting surface and is typically used to study surface deformations. Amplitude, on the other hand, is a measure of the strength of backscattered signal from the ground and is typically used to characterize objects on the ground [<ce:cross-ref id="cf0105" refid="bb0090">18</ce:cross-ref>]. The normalized measure of amplitude per unit area of a distributed target is called backscatter coefficient (<ce:italic>σ</ce:italic>
                     <ce:inf loc="post">0</ce:inf>). <ce:italic>σ</ce:italic>
                     <ce:inf loc="post">0</ce:inf> depends on the surface roughness and can, therefore, be used to measure the quality of pavement surfaces [<ce:cross-refs id="cf0110" refid="bb0090 bb0095 bb0100">18–20</ce:cross-refs>]. A smooth pavement (<ce:cross-ref id="cf0115" refid="f0005">Fig. 1</ce:cross-ref>a<ce:float-anchor refid="f0005"/>) will act similar to a mirror and reflect all the incident energy in the opposite direction. As a result, the backscattering coefficient will be low for smooth pavements [<ce:cross-ref id="cf0120" refid="bb0105">21</ce:cross-ref>] as compared to the pavements with greater roughness (<ce:cross-ref id="cf0125" refid="f0005">Fig. 1</ce:cross-ref>b and <ce:cross-ref id="cf0130" refid="f0005">Fig. 1</ce:cross-ref>c). Based on this principle, smooth surfaces will result in low <ce:italic>σ</ce:italic>
                     <ce:inf loc="post">0</ce:inf> values than the rough surfaces and these surfaces are represented with darker pixels in a SAR image.</ce:para>
                  <ce:para id="p0050" view="all">Despite the working principle of SAR imagery is promising to quantify pavement roughness, the interpretation of SAR backscatters from pavements is not straightforward. SAR data presents a number of practical challenges that are described below and addressed in the proposed framework. The first challenge is related to traffic noise, as pavement backscatters are greatly affected when vehicles and other objects are present on the road. In the presence of traffic (<ce:cross-ref id="cf0135" refid="f0010">Fig. 2</ce:cross-ref>
                     <ce:float-anchor refid="f0010"/>), the SAR signal will suffer a double bounce effect and result in higher backscatter coefficients represented with brighter pixels. A smooth pavement may therefore appear brighter due to the presence of traffic, objects, trees, and tall buildings near the roads. Therefore, it is essential to filter out the reflected signals from traffic and other similar obstructions on or near the roads to accurately model road surface condition from SAR backscatters.</ce:para>
                  <ce:para id="p0055" view="all">Similar to traffic noise, SAR images suffer from speckle noise when backscatters from different individual ground scatterers interfere with each other, resulting in either strong or weak return signals. This gives the SAR images a grainy appearance. To ensure accurate relationships between pavement condition and SAR responses, it is necessary to remove these speckles from SAR images. Lee filter is commonly used as an effective solution to suppress speckles in SAR images [<ce:cross-ref id="cf0140" refid="bb0115">23</ce:cross-ref>]. Lee filter, however, fails to preserve the edges and texture of the linear features well, which are critical in roadway applications. While pavement related studies [<ce:cross-ref id="cf0145" refid="bb0105">21</ce:cross-ref>,<ce:cross-ref id="cf0150" refid="bb0120">24</ce:cross-ref>] have applied several different filters to deal with speckles, the performance of these filters have not been evaluated quantitively.</ce:para>
                  <ce:para id="p0060" view="all">Also, there is no agreement on the most effective polarization of radar signals to capture pavement roughness. The polarization (i.e., orientation of the plane of oscillation) of a propagating signal affects how a signal interacts with an object on the ground. Since SAR has its own source of illumination, it can control the polarization of both the transmitted and backscattered signal. A vertical-vertical (VV) polarization indicates that the radar signals are transmitted and received vertically. Similarly, a vertical-horizontal (VH) polarization means the radar signals are transmitted vertically and received horizontally. Meyer et al. [<ce:cross-ref id="cf0155" refid="bb0120">24</ce:cross-ref>] found VV polarization to be highly sensitive to rough surface scattering and recommended it for investigating roads and paved surfaces. Suanpaga and Yoshikazu [<ce:cross-ref id="cf0160" refid="bb0100">20</ce:cross-ref>], however, found HH polarization to be the most useful for modeling the International Roughness Index (IRI) of pavements.</ce:para>
                  <ce:para id="p0065" view="all">Furthermore, the terrain contained in the pre-processed SAR images introduce geometric distortions due to the side-looking imaging technique of SAR systems. This results in over and under exposed pixels creating a barrier in correlating backscatter strengths to condition of the pavements located in different terrains. To address these challenges, we propose a structured approach that effectively improves post-processing of SAR images for pavement applications.</ce:para>
               </ce:section>
               <ce:section id="s0020" view="all">
                  <ce:label>3</ce:label>
                  <ce:section-title id="st0035">Proposed framework</ce:section-title>
                  <ce:para id="p0070" view="all">This paper introduces a novel framework to leverage SAR imagery and deep learning in estimating pavement roughness. The proposed framework (summarized in <ce:cross-ref id="cf0165" refid="f0015">Fig. 3</ce:cross-ref>
                     <ce:float-anchor refid="f0015"/>) provides a process that improves the standard SAR data processing method [<ce:cross-ref id="cf0170" refid="bb0110">22</ce:cross-ref>] to better address the issues associated with using SAR to monitor pavements. Our framework provides guidance on the polarization channel that should be used to capture pavement roughness, which filters should be applied to remove speckles without compromising the linear road features, and how to remove traffic noise and the effect of terrain to accurately model pavement condition from SAR backscatters. Once these processes are completed, data is modeled using deep learning algorithms and results in a predictive tool that is developed, tested, and ultimately deployed. The critical components of the proposed framework are discussed in detail in the subsequent sections.</ce:para>
                  <ce:section id="s0025" view="all">
                     <ce:label>3.1</ce:label>
                     <ce:section-title id="st0040">Data processing</ce:section-title>
                     <ce:section id="s0030" view="all">
                        <ce:label>3.1.1</ce:label>
                        <ce:section-title id="st0045">Post-process SAR image</ce:section-title>
                        <ce:para id="p0075" view="all">The proposed framework leverages SAR imagery captured by the Sentinel-1 satellite and, more specifically, the pre-processed Level-1 ground range detected high resolution dataset acquired from the Alaska Satellite Facility [<ce:cross-ref id="cf0175" refid="bb0125">25</ce:cross-ref>]. The acquired imagery typically have geometric and radiometric distortions due to the oblique observation geometry. These data, therefore, requires post-processing before they can be analyzed in a geographic information system (GIS) environment. Standard routine in post-processing these data include applying precise orbit file, radiometric calibration, speckle filter, radiometric terrain flattening, and geometric terrain correction. In this paper, we recommend a standard post-processing routine for pavement applications. Readers interested in a more detailed review of these processes can refer to [<ce:cross-ref id="cf0180" refid="bb0110">22</ce:cross-ref>].</ce:para>
                        <ce:section id="s0035" view="all">
                           <ce:label>3.1.1.1</ce:label>
                           <ce:section-title id="st0050">Select effective polarization</ce:section-title>
                           <ce:para id="p0080" view="all">Radar sensors typically collect data in multiple polarizations. The backscatters received for the same object on the ground varies based on the polarization channel of a sensor. Therefore, using the image captured in a polarization that is more sensitive to pavement roughness is of utmost importance in modeling IRI using SAR backscatters. Given the lack of agreement on what polarization channel is more effective for pavement applications, the first step of the proposed framework is to explore the suitability of Sentinel-1 polarization channels (i.e., VV and VH). SAR responses along the roads from both the VV and VH images were compared against their corresponding levels of roughness to quantify the ability of these channels at capturing differences in pavement condition.</ce:para>
                        </ce:section>
                        <ce:section id="s0040" view="all">
                           <ce:label>3.1.1.2</ce:label>
                           <ce:section-title id="st0055">Speckle filtering</ce:section-title>
                           <ce:para id="p0085" view="all">To remove speckles, especially from the pavement pixels, six different adaptive filters were considered in this study: Lee, Frost, Gamma-map, Intensity Driven Adaptive Neighborhood (IDAN), Refined Lee, and Lee Sigma. The goal of this analysis is to identify the filter that is most effective in suppressing speckles from pavement pixels while preserving the sharpness of edges and linear road features. The effectiveness of these filters was assessed using the following metrics:<ce:list id="l0010">
                                 <ce:list-item id="li0030">
                                    <ce:label>•</ce:label>
                                    <ce:para id="p0090" view="all">Speckle Noise Index (SNI): This index measures the intensity of speckle noise in an image. Lower SNI values indicate better speckle noise suppression. SNI is defined as follows [<ce:cross-ref id="cf0185" refid="bb0130">26</ce:cross-ref>]:</ce:para>
                                 </ce:list-item>
                              </ce:list>
                              <ce:display>
                                 <ce:formula id="fo0005">
                                    <ce:label>(1)</ce:label>
                                    <mml:math altimg="si1.svg">
                                       <mml:maligngroup/>
                                       <mml:mi mathvariant="italic">SNI</mml:mi>
                                       <mml:mo linebreak="goodbreak">=</mml:mo>
                                       <mml:mfrac>
                                          <mml:mi>σ</mml:mi>
                                          <mml:mi>μ</mml:mi>
                                       </mml:mfrac>
                                       <mml:mspace width="0.25em"/>
                                    </mml:math>
                                 </ce:formula>
                              </ce:display>
                           </ce:para>
                           <ce:para id="p0095" view="all">Where, <ce:italic>μ</ce:italic> and <ce:italic>σ</ce:italic> are the mean and standard deviation of the filtered image.<ce:list id="l0015">
                                 <ce:list-item id="li0035">
                                    <ce:label>•</ce:label>
                                    <ce:para id="p0100" view="all">Equivalent Number of Looks (ENL): To smooth out noises, ground range detected (i.e., phase information removed) SAR images are subject to multi-looking (i.e., averaging the intensity of neighboring pixels) during the pre-processing. This concept of multi-looking was used to coin the term Equivalent Number of Looks (ENL), which is a measure of the degree of speckle suppression in post-processing. While ENL is similar to SNI, the second power in the formulation is useful in differentiating among similarly performing filters. Higher ENL indicates greater speckle suppression at the expense of edges and texture information. The choice of an ideal filter is, therefore, a compromise between noise removal and details preservation. ENL is estimated as [<ce:cross-ref id="cf0190" refid="bb0135">27</ce:cross-ref>]:</ce:para>
                                 </ce:list-item>
                              </ce:list>
                              <ce:display>
                                 <ce:formula id="fo0010">
                                    <ce:label>(2)</ce:label>
                                    <mml:math altimg="si2.svg">
                                       <mml:mtable displaystyle="true">
                                          <mml:mtr>
                                             <mml:mtd>
                                                <mml:mi mathvariant="italic">ENL</mml:mi>
                                                <mml:mo linebreak="goodbreak">=</mml:mo>
                                                <mml:msup>
                                                   <mml:mfenced open="(" close=")">
                                                      <mml:mfrac>
                                                         <mml:mi>μ</mml:mi>
                                                         <mml:mi>σ</mml:mi>
                                                      </mml:mfrac>
                                                   </mml:mfenced>
                                                   <mml:mn>2</mml:mn>
                                                </mml:msup>
                                                <mml:mspace width="0.25em"/>
                                             </mml:mtd>
                                          </mml:mtr>
                                       </mml:mtable>
                                    </mml:math>
                                 </ce:formula>
                              </ce:display>
                              <ce:list id="l0020">
                                 <ce:list-item id="li0040">
                                    <ce:label>•</ce:label>
                                    <ce:para id="p0105" view="all">Normalized Mean (NM): This metric is used to evaluate if a filter results in an unbiased estimate. It is estimated as follows [<ce:cross-ref id="cf0195" refid="bb0140">28</ce:cross-ref>], with NM values close to 1 indicating that the original information was perfectly preserved [<ce:cross-ref id="cf0200" refid="bb0145">29</ce:cross-ref>].</ce:para>
                                 </ce:list-item>
                              </ce:list>
                              <ce:display>
                                 <ce:formula id="fo0015">
                                    <ce:label>(3)</ce:label>
                                    <mml:math altimg="si3.svg">
                                       <mml:mtable displaystyle="true">
                                          <mml:mtr>
                                             <mml:mtd>
                                                <mml:mi mathvariant="italic">NM</mml:mi>
                                                <mml:mo linebreak="goodbreak">=</mml:mo>
                                                <mml:mfrac>
                                                   <mml:msub>
                                                      <mml:mi>μ</mml:mi>
                                                      <mml:mi mathvariant="italic">filtered</mml:mi>
                                                   </mml:msub>
                                                   <mml:msub>
                                                      <mml:mi>μ</mml:mi>
                                                      <mml:mi mathvariant="italic">original</mml:mi>
                                                   </mml:msub>
                                                </mml:mfrac>
                                                <mml:mspace width="0.25em"/>
                                             </mml:mtd>
                                          </mml:mtr>
                                       </mml:mtable>
                                    </mml:math>
                                 </ce:formula>
                              </ce:display>
                           </ce:para>
                           <ce:para id="p0110" view="all">Where, <ce:italic>μ</ce:italic>
                              <ce:inf loc="post">
                                 <ce:italic>filtered</ce:italic>
                              </ce:inf> and <ce:italic>μ</ce:italic>
                              <ce:inf loc="post">
                                 <ce:italic>original</ce:italic>
                              </ce:inf> is the mean of the pixel values before and after filtering the image.</ce:para>
                        </ce:section>
                        <ce:section id="s0045" view="all">
                           <ce:label>3.1.1.3</ce:label>
                           <ce:section-title id="st0060">Radiometric terrain correction</ce:section-title>
                           <ce:para id="p0115" view="all">Each pixel of a Level-1 pre-processed SAR image essentially indicates the value of a backscatter coefficient (<ce:italic>σ</ce:italic>
                              <ce:inf loc="post">0</ce:inf>) resulting from the measured return signals. As a result, this image is often referred to as a Sigma Naught image. This image, however, suffers from the effect of topography, resulting in misleading <ce:italic>σ</ce:italic>
                              <ce:inf loc="post">0</ce:inf> values for locations where the signals are affected by an uneven terrain. Rather than capturing straight-down, the SAR sensors use a side-looking imaging technique which causes geometric distortions leading to geolocation errors. This worsens in the presence of slopes, resulting in deceptive <ce:italic>σ</ce:italic>
                              <ce:inf loc="post">0</ce:inf>. Since the proposed framework is based on measures of SAR amplitude (i.e., strength of the backscatter), it is critical to apply radiometric terrain correction to ensure accurate measurement of backscatters. Radiometric terrain correction refers to the process of removing the influence of topography from SAR images. This process moves the SAR pixels into correct spatial relationship to each other and the corrected backscatter coefficients are denoted by <ce:italic>γ</ce:italic>
                              <ce:inf loc="post">0</ce:inf>. Therefore, the resulting image is referred to as a Gamma Naught image, where each pixel of the image indicates the value of corrected backscatter coefficient <ce:italic>γ</ce:italic>
                              <ce:inf loc="post">0</ce:inf>.</ce:para>
                        </ce:section>
                     </ce:section>
                     <ce:section id="s0050" view="all">
                        <ce:label>3.1.2</ce:label>
                        <ce:section-title id="st0065">Remove traffic noise</ce:section-title>
                        <ce:para id="p0120" view="all">To remove traffic or any other temporary noise from the pavement pixels, the framework recommends an image stacking solution. With this approach, multiple images collected within a time window are bundled together. The stack is then used to generate a minimum intensity projection image where each pixel intensity is the minimum of all the pixels at that location across all the images in the stack. Traffic or other temporary objects on road create stronger backscatter (i.e., brighter pixels). Since the minimum intensity projection filters out the brighter spots which are not present in all the images, the temporary noises are removed while the brighter signals from permanent objects are preserved as they are similarly bright in all the images of the stack. Including a large number of images in the stack would increase the probability of filtering out heavy traffic noise. Given the proposed stacking solution requires a time window for image acquisition, a seasonal variability analysis of SAR responses was performed to derive recommendations on how to select this time window for a specific region. An example of this method applied to the pavements in Minnesota is described in the ‘Case Study’ section.</ce:para>
                     </ce:section>
                     <ce:section id="s0055" view="all">
                        <ce:label>3.1.3</ce:label>
                        <ce:section-title id="st0070">Extract SAR responses</ce:section-title>
                        <ce:para id="p0125" view="all">To extract backscatters from SAR images along the roads, a road network shapefile is first created based on the location information stored in the pavement features dataset. Then, reference points are generated along the road lines at a distance equal to the size of a pixel (i.e., spatial resolution) as illustrated in <ce:cross-ref id="cf0205" refid="f0020">Fig. 4</ce:cross-ref>(a)<ce:float-anchor refid="f0020"/> with a satellite image in the background. These reference points are carefully reviewed to remove any points where the backscatters are not representative of the pavement condition. For example, traffic signals, signposts, overpasses, or any other visible objects on or near the road are not included in the extraction, as they cause double bounce scatters and result in stronger backscatters. An example of this is shown by overlaying the reference points on top of a SAR image in <ce:cross-ref id="cf0210" refid="f0020">Fig. 4</ce:cross-ref>(b), where an overpass causes significantly higher backscatters that result in a high pixel value (i.e., bright pixels). The final reference points are then used to extract <ce:italic>γ</ce:italic>
                           <ce:inf loc="post">0</ce:inf> values along the roads. Pavement conditions are typically reported every 0.1 mile, extracted <ce:italic>γ</ce:italic>
                           <ce:inf loc="post">0</ce:inf> values are, therefore, averaged over every 0.1 mile.</ce:para>
                     </ce:section>
                     <ce:section id="s0060" view="all">
                        <ce:label>3.1.4</ce:label>
                        <ce:section-title id="st0075">Compile final dataset</ce:section-title>
                        <ce:para id="p0130" view="all">The average <ce:italic>γ</ce:italic>
                           <ce:inf loc="post">0</ce:inf> values are then labeled with the IRI for corresponding sections. Additional features of these sections such as surface type (i.e., concrete or asphalt), age (i.e., measured as number of years since last major maintenance or construction), thickness of the surface layer, thickness of the base layer, and average annual daily traffic (AADT) are included as pavement features in the final dataset.</ce:para>
                     </ce:section>
                  </ce:section>
                  <ce:section id="s0065" view="all">
                     <ce:label>3.2</ce:label>
                     <ce:section-title id="st0080">Deep learning tool</ce:section-title>
                     <ce:section id="s0070" view="all">
                        <ce:label>3.2.1</ce:label>
                        <ce:section-title id="st0085">Model development</ce:section-title>
                        <ce:para id="p0135" view="all">To leverage the improvements resulted from the proposed framework a Deep Neural Network model is developed to estimate pavement IRI from the processed SAR imagery. To account for the uncertainties associated with the point predictions of IRI, a Gradient Boosting Machine model is also developed. The Gradient Boosting Machine model is used to estimate prediction intervals for corresponding estimations of IRI from the Deep Neural Network model. For both models, the dataset is split into 80% for training and 20% for testing.</ce:para>
                        <ce:section id="s0075" view="all">
                           <ce:label>3.2.1.1</ce:label>
                           <ce:section-title id="st0090">IRI prediction</ce:section-title>
                           <ce:para id="p0140" view="all">The Keras API with Tensorflow backend is used to define a sequential Deep Neural Network model which uses the feedforward backpropagation algorithm to learn from the training samples. The input layer consisted of 6 neurons with 1 neuron in the output layer. A normalization layer is added before the input layer to scale the features for efficient computation. Several different combinations of number of hidden layers, number of neurons in each hidden layers, and activation functions are tested to identify the optimum model architecture. Adam optimizer with a decaying learning rate starting from 0.001 is used to train the model to facilitate both better optimization and generalization. To prevent the model from overfitting, a smaller batch size of 100 samples is used. The training is stopped early for the same purpose by monitoring the performance of the model on a validation set with 20% of training samples. The optimum architecture of the final Deep Neural Network model consisted of 2 hidden layers with 24 neurons in the first and 18 neurons in the second hidden layer. For both the hidden layers, Rectified Linear Unit (ReLu) activation resulted in the best performance.</ce:para>
                        </ce:section>
                        <ce:section id="s0080" view="all">
                           <ce:label>3.2.1.2</ce:label>
                           <ce:section-title id="st0095">Prediction intervals</ce:section-title>
                           <ce:para id="p0145" view="all">A Gradient Boosting Machine (GBM) model is trained to estimate the errors produced by the Deep Neural Network model. GBM algorithm makes predictions by averaging results obtained from an ensemble of decision trees. These trees are completely different from one another based on the features they use to make decisions at each node. Each of these trees are trained sequentially in a way that they try to minimize the errors made by the previous trees, which results in a successive decrease of error in subsequent tree ensemble. This leads to a greater prediction accuracy [<ce:cross-ref id="cf0215" refid="bb0150">30</ce:cross-ref>] and both faster and efficient computation as compared to neural networks [<ce:cross-ref id="cf0220" refid="bb0155">31</ce:cross-ref>]. GBM is also commonly used to estimate prediction intervals to quantify the uncertainties associated with point estimates [<ce:cross-ref id="cf0225" refid="bb0160">32</ce:cross-ref>]. Therefore, to estimate the prediction intervals for the point IRI estimates, the errors are calculated first by squaring the difference between the predicted and actual IRI. Then the Gradient Boosting Regressor algorithm from the scikit-learn library is used to fit the GBM model for errors. A grid-search approach covering a range of learning rates, number of boosting states, minimum number of samples required to split an internal node, minimum number of samples required to be at a leaf node, and maximum depth of individual regression estimators is used to optimize the model. The standard deviation for each IRI prediction is computed by taking the root of the error predicted by the Gradient Boosting Machine model. The standard deviation is finally adjusted to construct the prediction interval around a predicted IRI.</ce:para>
                        </ce:section>
                     </ce:section>
                     <ce:section id="s0085" view="all">
                        <ce:label>3.2.2</ce:label>
                        <ce:section-title id="st0100">Model testing</ce:section-title>
                        <ce:para id="p0150" view="all">The most commonly reported metrics to evaluate the goodness-of-fit of regression models in pavement research are the coefficient of determination (<ce:italic>R</ce:italic>
                           <ce:sup loc="post">2</ce:sup>), Root Mean Squared Error (RMSE), and Mean Absolute Error (MAE) [<ce:cross-refs id="cf0230" refid="bb0165 bb0170 bb0175 bb0180 bb0185">33–37</ce:cross-refs>]. <ce:italic>R</ce:italic>
                           <ce:sup loc="post">2</ce:sup> measures the variance in target variable explained by the independent variables. Although it is often very misleading as inclusion of more variables always result in higher <ce:italic>R</ce:italic>
                           <ce:sup loc="post">2</ce:sup> values, it was reported in this paper considering similar studies. MAE describes the average error and RMSE is more useful in limiting larger errors as they assign relatively higher weight to larger errors (i.e., the errors are squared before averaging). The performance of the models during the training and testing phases were evaluated in terms of the following metrics:<ce:display>
                              <ce:formula id="fo0020">
                                 <ce:label>(4)</ce:label>
                                 <mml:math altimg="si4.svg">
                                    <mml:mtable displaystyle="true">
                                       <mml:mtr>
                                          <mml:mtd>
                                             <mml:msup>
                                                <mml:mi>R</mml:mi>
                                                <mml:mn>2</mml:mn>
                                             </mml:msup>
                                             <mml:mo linebreak="goodbreak">=</mml:mo>
                                             <mml:mn>1</mml:mn>
                                             <mml:mo linebreak="badbreak">−</mml:mo>
                                             <mml:mfrac>
                                                <mml:mrow>
                                                   <mml:munderover>
                                                      <mml:mo>∑</mml:mo>
                                                      <mml:mrow>
                                                         <mml:mi>i</mml:mi>
                                                         <mml:mo>=</mml:mo>
                                                         <mml:mn>1</mml:mn>
                                                      </mml:mrow>
                                                      <mml:mi>n</mml:mi>
                                                   </mml:munderover>
                                                   <mml:msup>
                                                      <mml:mfenced open="(" close=")">
                                                         <mml:mrow>
                                                            <mml:msub>
                                                               <mml:mi mathvariant="italic">IRI</mml:mi>
                                                               <mml:mi>i</mml:mi>
                                                            </mml:msub>
                                                            <mml:mo linebreak="badbreak">−</mml:mo>
                                                            <mml:mover accent="true">
                                                               <mml:msub>
                                                                  <mml:mi mathvariant="italic">IRI</mml:mi>
                                                                  <mml:mi>i</mml:mi>
                                                               </mml:msub>
                                                               <mml:mo stretchy="true">̂</mml:mo>
                                                            </mml:mover>
                                                         </mml:mrow>
                                                      </mml:mfenced>
                                                      <mml:mn>2</mml:mn>
                                                   </mml:msup>
                                                </mml:mrow>
                                                <mml:mrow>
                                                   <mml:munderover>
                                                      <mml:mo>∑</mml:mo>
                                                      <mml:mrow>
                                                         <mml:mi>i</mml:mi>
                                                         <mml:mo>=</mml:mo>
                                                         <mml:mn>1</mml:mn>
                                                      </mml:mrow>
                                                      <mml:mi>n</mml:mi>
                                                   </mml:munderover>
                                                   <mml:msup>
                                                      <mml:mfenced open="(" close=")">
                                                         <mml:mrow>
                                                            <mml:msub>
                                                               <mml:mi mathvariant="italic">IRI</mml:mi>
                                                               <mml:mi>i</mml:mi>
                                                            </mml:msub>
                                                            <mml:mo linebreak="badbreak">−</mml:mo>
                                                            <mml:mover accent="true">
                                                               <mml:msub>
                                                                  <mml:mi mathvariant="italic">IRI</mml:mi>
                                                                  <mml:mi>i</mml:mi>
                                                               </mml:msub>
                                                               <mml:mo stretchy="true">¯</mml:mo>
                                                            </mml:mover>
                                                         </mml:mrow>
                                                      </mml:mfenced>
                                                      <mml:mn>2</mml:mn>
                                                   </mml:msup>
                                                </mml:mrow>
                                             </mml:mfrac>
                                             <mml:mspace width="0.25em"/>
                                          </mml:mtd>
                                       </mml:mtr>
                                    </mml:mtable>
                                 </mml:math>
                              </ce:formula>
                           </ce:display>
                           <ce:display>
                              <ce:formula id="fo0025">
                                 <ce:label>(5)</ce:label>
                                 <mml:math altimg="si5.svg">
                                    <mml:mtable displaystyle="true">
                                       <mml:mtr>
                                          <mml:mtd>
                                             <mml:mi mathvariant="italic">MAE</mml:mi>
                                             <mml:mo linebreak="goodbreak">=</mml:mo>
                                             <mml:mfrac>
                                                <mml:mn>1</mml:mn>
                                                <mml:mi>n</mml:mi>
                                             </mml:mfrac>
                                             <mml:munderover>
                                                <mml:mo>∑</mml:mo>
                                                <mml:mrow>
                                                   <mml:mi>i</mml:mi>
                                                   <mml:mo>=</mml:mo>
                                                   <mml:mn>1</mml:mn>
                                                </mml:mrow>
                                                <mml:mi>n</mml:mi>
                                             </mml:munderover>
                                             <mml:mfenced open="|" close="|">
                                                <mml:mrow>
                                                   <mml:mi mathvariant="italic">IR</mml:mi>
                                                   <mml:msub>
                                                      <mml:mi>I</mml:mi>
                                                      <mml:mi>i</mml:mi>
                                                   </mml:msub>
                                                   <mml:mo linebreak="badbreak">−</mml:mo>
                                                   <mml:msub>
                                                      <mml:mover accent="true">
                                                         <mml:mi mathvariant="italic">IRI</mml:mi>
                                                         <mml:mo stretchy="true">̂</mml:mo>
                                                      </mml:mover>
                                                      <mml:mi>i</mml:mi>
                                                   </mml:msub>
                                                </mml:mrow>
                                             </mml:mfenced>
                                             <mml:mspace width="0.25em"/>
                                          </mml:mtd>
                                       </mml:mtr>
                                    </mml:mtable>
                                 </mml:math>
                              </ce:formula>
                           </ce:display>
                           <ce:display>
                              <ce:formula id="fo0030">
                                 <ce:label>(6)</ce:label>
                                 <mml:math altimg="si6.svg">
                                    <mml:mtable displaystyle="true">
                                       <mml:mtr>
                                          <mml:mtd>
                                             <mml:mi mathvariant="italic">RMSE</mml:mi>
                                             <mml:mo linebreak="goodbreak">=</mml:mo>
                                             <mml:msqrt>
                                                <mml:mrow>
                                                   <mml:mfrac>
                                                      <mml:mn>1</mml:mn>
                                                      <mml:mi>n</mml:mi>
                                                   </mml:mfrac>
                                                   <mml:munderover>
                                                      <mml:mo>∑</mml:mo>
                                                      <mml:mrow>
                                                         <mml:mi>i</mml:mi>
                                                         <mml:mo>=</mml:mo>
                                                         <mml:mn>1</mml:mn>
                                                      </mml:mrow>
                                                      <mml:mi>n</mml:mi>
                                                   </mml:munderover>
                                                   <mml:msup>
                                                      <mml:mfenced open="(" close=")">
                                                         <mml:mrow>
                                                            <mml:mi mathvariant="italic">IR</mml:mi>
                                                            <mml:msub>
                                                               <mml:mi>I</mml:mi>
                                                               <mml:mi>i</mml:mi>
                                                            </mml:msub>
                                                            <mml:mo linebreak="badbreak">−</mml:mo>
                                                            <mml:msub>
                                                               <mml:mover accent="true">
                                                                  <mml:mi mathvariant="italic">IRI</mml:mi>
                                                                  <mml:mo stretchy="true">̂</mml:mo>
                                                               </mml:mover>
                                                               <mml:mi>i</mml:mi>
                                                            </mml:msub>
                                                         </mml:mrow>
                                                      </mml:mfenced>
                                                      <mml:mn>2</mml:mn>
                                                   </mml:msup>
                                                </mml:mrow>
                                             </mml:msqrt>
                                          </mml:mtd>
                                       </mml:mtr>
                                    </mml:mtable>
                                 </mml:math>
                              </ce:formula>
                           </ce:display>
                        </ce:para>
                     </ce:section>
                  </ce:section>
               </ce:section>
               <ce:section id="s0090" role="case-study" view="all">
                  <ce:label>4</ce:label>
                  <ce:section-title id="st0105">Case study</ce:section-title>
                  <ce:para id="p0155" view="all">To evaluate the capabilities of the proposed framework, a case study analyzing the Minnesota's trunk highway network was undertaken. Minnesota Department of Transportation's (MnDOT) trunk highway system is composed of approximately 14,300 roadway miles of pavement. The entire trunk highway system is surveyed annually to record pavement roughness and surface distresses since the late 1960s [<ce:cross-ref id="cf0235" refid="bb0190">38</ce:cross-ref>]. For this project, pavements within the Metro District, covering an area of 3237 mile<ce:sup loc="post">2</ce:sup> were analyzed.</ce:para>
                  <ce:section id="s0095" view="all">
                     <ce:label>4.1</ce:label>
                     <ce:section-title id="st0110">Pavement condition and feature data</ce:section-title>
                     <ce:para id="p0160" view="all">The condition of pavements in the area of study was surveyed using a digital inspection vehicle driven on the outer lane of all trunk highways [<ce:cross-ref id="cf0240" refid="bb0190">38</ce:cross-ref>]. Three laser sensors mounted on the front bumper of the vehicle recorded roughness and faulting on both the wheel paths and center of the lane. IRI is estimated as the ratio of a standard vehicle's accumulated suspension motion (inches) and the distance traveled by the vehicle during the measurement period (miles) [<ce:cross-ref id="cf0245" refid="bb0100">20</ce:cross-ref>]. This process follows the ASTM E 1926 specifications, where a quarter-car is driven along the longitudinal profile at a speed of 50 miles/h and the suspension deflection is estimated using measured profile displacement and standard car structure values [<ce:cross-ref id="cf0250" refid="bb0195">39</ce:cross-ref>]. Smooth roads result in smaller accumulation of suspension deflection resulting low IRI and rough roads result in high IRI values as illustrated in <ce:cross-ref id="cf0255" refid="f0025">Fig. 5</ce:cross-ref>
                        <ce:float-anchor refid="f0025"/>. Two lasers mounted on the back of the vehicle were used to capture 3D images of the pavement surface for rut measurements. A camera mounted on the back of the vehicle was used to capture pavement distresses such as cracking and patching. The distresses were recorded at every 1/8 in. as the van traveled at a driving speed, although the measurements were processed at every 0.1 mile. For this study, the pavement condition dataset included IRI data for the entire trunk highway network at every 0.1-mile. In addition to this, pavement features such as age, surface type, layer thicknesses, base type, traffic, and maintenance history (i.e., time and type of last maintenance activity), reference points and their coordinates for the corresponding 0.1-mile segments were compiled to produce a pavement features dataset.</ce:para>
                     <ce:para id="p0165" view="all">In terms of pavement condition indices, this study analyzed pavement roughness (i.e., measured in terms of IRI) and Ride Quality Index (RQI). We decided to use IRI because it is a well-recognized pavement performance indicator and transportation agencies around the world use IRI to measure road surface roughness [<ce:cross-ref id="cf0260" refid="bb0035">7</ce:cross-ref>,<ce:cross-ref id="cf0265" refid="bb0200">40</ce:cross-ref>]. RQI, in turn, is estimated to reflect the users' perceived roughness while driving on a road. To develop a correlation between IRI and RQI, MnDOT asked 32 citizens to rate 120 test sections with different levels of roughness. After driving on each of the 0.25-mile test sections, the panelists rated the quality of their rides on a scale of 0 to 5 based on how they felt about the roughness of these roads. Based on these ratings, the following equations were developed to estimate RQI for asphalt and concrete pavements [<ce:cross-ref id="cf0270" refid="bb0205">41</ce:cross-ref>]:<ce:display>
                           <ce:formula id="fo0035">
                              <ce:label>(7)</ce:label>
                              <mml:math altimg="si7.svg">
                                 <mml:mtable displaystyle="true">
                                    <mml:mtr>
                                       <mml:mtd>
                                          <mml:mi mathvariant="italic">RQ</mml:mi>
                                          <mml:msub>
                                             <mml:mi>I</mml:mi>
                                             <mml:mi mathvariant="italic">asphalt</mml:mi>
                                          </mml:msub>
                                          <mml:mo linebreak="goodbreak">=</mml:mo>
                                          <mml:mn>5.697</mml:mn>
                                          <mml:mo linebreak="badbreak">−</mml:mo>
                                          <mml:mn>0.264</mml:mn>
                                          <mml:mo linebreak="badbreak">×</mml:mo>
                                          <mml:msqrt>
                                             <mml:mi mathvariant="italic">IRI</mml:mi>
                                          </mml:msqrt>
                                          <mml:mspace width="0.25em"/>
                                       </mml:mtd>
                                    </mml:mtr>
                                 </mml:mtable>
                              </mml:math>
                           </ce:formula>
                        </ce:display>
                        <ce:display>
                           <ce:formula id="fo0040">
                              <ce:label>(8)</ce:label>
                              <mml:math altimg="si8.svg">
                                 <mml:mtable displaystyle="true">
                                    <mml:mtr>
                                       <mml:mtd>
                                          <mml:mi mathvariant="italic">RQ</mml:mi>
                                          <mml:msub>
                                             <mml:mi>I</mml:mi>
                                             <mml:mi mathvariant="italic">concrete</mml:mi>
                                          </mml:msub>
                                          <mml:mo linebreak="goodbreak">=</mml:mo>
                                          <mml:mn>6.634</mml:mn>
                                          <mml:mo linebreak="badbreak">−</mml:mo>
                                          <mml:mn>0.353</mml:mn>
                                          <mml:mo linebreak="badbreak">×</mml:mo>
                                          <mml:msqrt>
                                             <mml:mi mathvariant="italic">IRI</mml:mi>
                                          </mml:msqrt>
                                          <mml:mspace width="0.25em"/>
                                       </mml:mtd>
                                    </mml:mtr>
                                 </mml:mtable>
                              </mml:math>
                           </ce:formula>
                        </ce:display>
                     </ce:para>
                     <ce:para id="p0170" view="all">Where, IRI is the International Roughness Index of the pavements in inches/mile.</ce:para>
                     <ce:para id="p0175" view="all">RQI is an unitless quantity estimated on a numeric scale of 0 to 5, where 5 represents the smoothest ride possible. Newly constructed roads have RQI values &gt;4, whereas pavements are typically rehabilitated for a terminal RQI value of 2.5. MnDOT road categories based RQI are given in <ce:cross-ref id="cf0275" refid="t0005">Table 1</ce:cross-ref>
                        <ce:float-anchor refid="t0005"/>.</ce:para>
                     <ce:para id="p0180" view="all">RQI was deemed a valuable indicator of condition, in addition to IRI, because it allows to categorize roughness into a few ordinal categories. Also, RQI is one of the indices currently used by MnDOT for decision-making purposes.</ce:para>
                  </ce:section>
                  <ce:section id="s0100" view="all">
                     <ce:label>4.2</ce:label>
                     <ce:section-title id="st0115">SAR imagery</ce:section-title>
                     <ce:para id="p0185" view="all">For this project, 91 SAR images captured by Sentinel-1 satellite were obtained from the Alaska Satellite Facility (ASF) [<ce:cross-ref id="cf0280" refid="bb0210">42</ce:cross-ref>]. The Sentinel-1 constellation is comprised of two polar orbiting satellites (1A and 1B) which images the earth using a C-band SAR sensor. To keep traffic interferences to a minimum, images from 1A satellite were analyzed in this project as it passes over the study area during midnight. The details of the collected data are summarized in <ce:cross-ref id="cf0285" refid="t0010">Table 2</ce:cross-ref>
                        <ce:float-anchor refid="t0010"/>.</ce:para>
                     <ce:para id="p0190" view="all">The acquired SAR imagery, in conjunction with the pavement features, and condition dataset were then processed using the framework proposed in <ce:cross-ref id="cf0290" refid="s0020">Section 3</ce:cross-ref>. The Data Processing module of the framework resulted in a dataset consisting of 5774 samples of road segments. For each segment, the dataset included surface type (asphalt/concrete), surface age in years, pavement layer thickness in inches, base thickness in inches, annual average daily traffic (AADT), <ce:italic>γ</ce:italic>
                        <ce:inf loc="post">0</ce:inf>, and IRI. The thickness of the pavements ranged from 2 to 16 in. with base layers ranging from 0 (i.e., no base layer) to 17 in. The age of the pavements ranged from 0 (i.e., newly constructed) to 66 years. However, only a smaller number of sections were found to have higher levels of roughness, as MnDOT maintains the trunk highway network at a very high standard. This resulted in a right-skewed distribution of the IRI values as shown in <ce:cross-ref id="cf0295" refid="f0030">Fig. 6</ce:cross-ref>(a)<ce:float-anchor refid="f0030"/>. The extracted <ce:italic>γ</ce:italic>
                        <ce:inf loc="post">0</ce:inf> values were also overserved to have a similar distribution with a slightly longer upper tail (<ce:cross-ref id="cf0300" refid="f0030">Fig. 6</ce:cross-ref>b).</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0105" view="all">
                  <ce:label>5</ce:label>
                  <ce:section-title id="st0120">Results</ce:section-title>
                  <ce:section id="s0110" view="all">
                     <ce:label>5.1</ce:label>
                     <ce:section-title id="st0125">Data processing</ce:section-title>
                     <ce:para id="p0195" view="all">This section describes the improvements in processed SAR data, specifically for the purpose of evaluating pavement condition, resulting from the proposed methodology.</ce:para>
                     <ce:section id="s0115" view="all">
                        <ce:label>5.1.1</ce:label>
                        <ce:section-title id="st0130">Selection of appropriate polarization</ce:section-title>
                        <ce:para id="p0200" view="all">The extracted <ce:italic>γ</ce:italic>
                           <ce:inf loc="post">0</ce:inf>values were observed to have a clear pattern when grouped together based on their RQI class (<ce:cross-ref id="cf0305" refid="f0035">Fig. 7</ce:cross-ref>
                           <ce:float-anchor refid="f0035"/>). Roads in poor condition exhibited stronger backscatters as compared to the roads in better condition, which is consistent with the concepts illustrated in <ce:cross-ref id="cf0310" refid="f0005">Fig. 1</ce:cross-ref> (i.e., rough surfaces scatter higher energy as compared to smooth surfaces). This trend is a strong indication of the potential of SAR data in evaluating pavement condition. <ce:cross-ref id="cf0315" refid="f0035">Fig. 7</ce:cross-ref> shows that the differences in backscatters for pavements in different condition is more evident in VV polarization compared to the VH polarization. Therefore, using the VV image would be more suitable in modeling pavement condition. This observation is aligned with the recommendations found in the literature [<ce:cross-ref id="cf0320" refid="bb0105">21</ce:cross-ref>,<ce:cross-ref id="cf0325" refid="bb0120">24</ce:cross-ref>].</ce:para>
                     </ce:section>
                     <ce:section id="s0120" view="all">
                        <ce:label>5.1.2</ce:label>
                        <ce:section-title id="st0135">Speckle suppression performance</ce:section-title>
                        <ce:para id="p0205" view="all">The performance of six speckle filters (i.e., Lee, Refined Lee, Lee Sigma, Gamma-map, Frost, and Intensity-Driven Adaptive Neighborhood (IDAN)) were tested to identify the most effective filter in suppressing speckles along the roads. While Lee filter is commonly used for filtering narrow road segments [<ce:cross-ref id="cf0330" refid="bb0105">21</ce:cross-ref>], comparative analysis of the filtered pavement pixels showed that IDAN and Refined Lee perform better than Lee in suppressing speckles across all the performance metrics (<ce:cross-ref id="cf0335" refid="f0040">Fig. 8</ce:cross-ref>
                           <ce:float-anchor refid="f0040"/>). IDAN resulted in significantly less speckles (<ce:italic>SNI</ce:italic> = 0.77) and offered higher equivalent number of looks (<ce:italic>ENL</ce:italic> = 1.68) as compared to Refined Lee (<ce:italic>SNI</ce:italic> = 1.03,<ce:hsp sp="0.12"/>
                           <ce:italic>ENL</ce:italic> = 0.93). Both IDAN (<ce:italic>NM</ce:italic> = 1.08) and Refined Lee (<ce:italic>NM</ce:italic> = 1.07) performed similarly in preserving original information along the roads. However, when it came to preserving the linear features and texture information, Refined Lee performed significantly better than IDAN and Lee (<ce:cross-ref id="cf0340" refid="f0045">Fig. 9</ce:cross-ref>
                           <ce:float-anchor refid="f0045"/>). Since preserving this information is critical for a road network, especially for narrower roads, Refined Lee filter is recommended to effectively suppress speckles along the road pixels.</ce:para>
                     </ce:section>
                     <ce:section id="s0125" view="all">
                        <ce:label>5.1.3</ce:label>
                        <ce:section-title id="st0140">Effect of radiometric terrain correction</ce:section-title>
                        <ce:para id="p0210" view="all">Radiometric terrain correction was found to be effective in removing the slope impacts on the SAR backscatters. While the backscatters from the highway network considered in this case study were not affected due to its flat terrain, <ce:cross-ref id="cf0345" refid="f0050">Fig. 10</ce:cross-ref>a<ce:float-anchor refid="f0050"/> shows that the roads located near the Mississippi riverbank were severely affected by the over exposed pixels. A radiometric terrain correction removes the influence of terrain on measured radar brightness (<ce:cross-ref id="cf0350" refid="f0050">Fig. 10</ce:cross-ref>b). Removing such local biases is essential in establishing meaningful insights from pavement backscatters over a large network. Therefore, it is recommended to apply a radiometric terrain correction as part of the SAR image post-processing in pavement applications.</ce:para>
                     </ce:section>
                     <ce:section id="s0130" view="all">
                        <ce:label>5.1.4</ce:label>
                        <ce:section-title id="st0145">Seasonal variability of SAR response</ce:section-title>
                        <ce:para id="p0215" view="all">Weather conditions such as snowfall and stagnant water in pavements can significantly influence the backscatter signals in SAR data. To better understand the impacts of weather conditions, we investigated the seasonal variations in SAR backscatter. The objective of this analysis is to identify the appropriate window for SAR data acquisition to avoid the effects of weather on SAR backscatter. One SAR image for each season for the years 2017 to 2019 were used to extract <ce:italic>γ</ce:italic>
                           <ce:inf loc="post">0</ce:inf> values at road reference points after making necessary radiometric and geometric adjustments. Backscatters in winter were constantly lower across all the years as compared to the other seasons (<ce:cross-ref id="cf4345" refid="f0055">Fig. 11</ce:cross-ref>
                           <ce:float-anchor refid="f0055"/>), possibly because of the snow reflecting most of the incident signal away. The same is true for spring 2018, when the Twin Cities area received about 26.1 in. of snowfall at the time the image was captured. This snowfall was significantly higher than the ones recorded in 2017 and 2019, which were &lt;8 in. over the month of April. These results confirm that snowfall significantly impacts the SAR backscatters.</ce:para>
                        <ce:para id="p0220" view="all">The backscatter pattern in Summer and Fall were found to be the most consistent over the years (<ce:cross-ref id="cf4350" refid="f0055">Fig. 11</ce:cross-ref>). Historical weather data for this area, however, indicates trace amount of snowfalls during the months of September and October [<ce:cross-ref id="cf0360" refid="bb0215">43</ce:cross-ref>]. Therefore, the SAR images captured during the summer (i.e., June–August) would be more appropriate to avoid the effects of snowfall. It is also recommended to carefully review the weather conditions for the dates of image acquisition at a specific location to exclude the images including snow from analysis. The remaining analyses of this project has been conducted based on the images acquired during a summer season only.</ce:para>
                     </ce:section>
                     <ce:section id="s0135" view="all">
                        <ce:label>5.1.5</ce:label>
                        <ce:section-title id="st0150">Removing traffic noise</ce:section-title>
                        <ce:para id="p0225" view="all">Images from Sentinel-1A collected during the months of June, July, and August were used to create stacks for different years. These stacks were then used to generate minimum intensity projection images for corresponding years. A visual comparison of the optical satellite images, individual SAR images, and the corresponding minimum intensity projection image indicated that the proposed methodology is highly effective in removing traffic and other temporary noises from the pavement pixels. For example, for the section shown <ce:cross-ref id="cf0365" refid="f0060">Fig. 12</ce:cross-ref>(a)<ce:float-anchor refid="f0060"/>, a SAR image captured on June 4, 2018, had a noise on the road surface (<ce:cross-ref id="cf0370" refid="f0060">Fig. 12</ce:cross-ref>(b)). While it cannot be confirmed as a noise coming from traffic, it was not present in any of the other images on the 2018 stack. The minimum intensity projection image, shown in <ce:cross-ref id="cf0375" refid="f0060">Fig. 12</ce:cross-ref>(c), was able successfully remove this temporary noise while preserving the backscatters coming from the permanent object such as the signposts. A careful inspection of all the minimum intensity projection images revealed a similar performance. Therefore, the proposed solution is recommended to effectively minimize traffic and other temporary noises from the road surfaces.</ce:para>
                     </ce:section>
                  </ce:section>
                  <ce:section id="s0140" view="all">
                     <ce:label>5.2</ce:label>
                     <ce:section-title id="st0155">Deep learning tool</ce:section-title>
                     <ce:section id="s0145" view="all">
                        <ce:label>5.2.1</ce:label>
                        <ce:section-title id="st0160">IRI prediction</ce:section-title>
                        <ce:para id="p0230" view="all">The optimal architecture of the Deep Neural Network model was found to be 6–24–18-1 with ReLu as the activation function for both the hidden layers. The model was able to achieve an <ce:italic>RMSE</ce:italic> of 19.41 in./mile, an <ce:italic>MAE</ce:italic> of 13.96 in./mile with and an <ce:italic>R</ce:italic>
                           <ce:sup loc="post">2</ce:sup> of 0.68. As illustrated in <ce:cross-ref id="cf0380" refid="f0065">Fig. 13</ce:cross-ref>
                           <ce:float-anchor refid="f0065"/>, a similar performance was obtained for the test set, indicating that the model does not suffer from overfitting. The predictive performance of the model was further investigated by analyzing the residuals. The residuals were observed to be randomly distributed along the range of predicted values, as shown in <ce:cross-ref id="cf0385" refid="f0070">Fig. 14</ce:cross-ref>a<ce:float-anchor refid="f0070"/>, indicating that the model does not suffer from heteroscedasticity. The Q-Q plot (<ce:cross-ref id="cf0390" refid="f0070">Fig. 14</ce:cross-ref>b) also confirms that the residuals are normally distributed. The right tail deviating upwards, however, is indicative of an inferior performance of the model for high IRI values (i.e., residuals are high for higher IRI values).</ce:para>
                        <ce:para id="p0235" view="all">The value added by the deep learning approach can be assessed when the performance of Deep Neural model is compared traditional regression models. A simple linear regression model performance for the same training set is shown <ce:cross-ref id="cf0395" refid="f0075">Fig. 15</ce:cross-ref>(a)<ce:float-anchor refid="f0075"/>, where IRI is predicted using the <ce:italic>γ</ce:italic>
                           <ce:inf loc="post">0</ce:inf> values extracted from the SAR imagery. The multiple linear regression model, as shown in <ce:cross-ref id="cf0400" refid="f0075">Fig. 15</ce:cross-ref>(b), is trained with all the features in the dataset. While the multiple linear regression model results in a slightly higher correlation between the actual and predicted IRI values, the Deep Neural Network model captures significantly higher amount of variability in data and results in smaller errors in predictions. A similar outcome is observed when the performance of the Deep Neural Network model is compared with the exponential regression model presented in Meyer et al. [<ce:cross-ref id="cf0405" refid="bb0120">24</ce:cross-ref>], which results in very high errors values (&gt;30 in./mile) for IRI values lower than 100 in./mile.</ce:para>
                     </ce:section>
                     <ce:section id="s0150" view="all">
                        <ce:label>5.2.2</ce:label>
                        <ce:section-title id="st0165">Prediction intervals</ce:section-title>
                        <ce:para id="p0240" view="all">The prediction intervals estimated from the Gradient Boosting Machine model were observed to capture 81% of the actual IRI values within their upper and lower limits. <ce:cross-ref id="cf0410" refid="f0080">Fig. 16</ce:cross-ref>
                           <ce:float-anchor refid="f0080"/> shows the estimated prediction intervals for 50 randomly sampled IRI predictions. This figure indicates that the prediction intervals can efficiently capture trends in actual IRI data. Higher values of the prediction intervals were associated with the most erroneous predictions. These examples are observed for the red dots located way outside of the interval limits in <ce:cross-ref id="cf0415" refid="f0080">Fig. 16</ce:cross-ref>. The uncertainties captured by these intervals largely stem from the coarser resolution of the SAR pixels. High resolution SAR images with smaller pixel sizes will help filtering out the noises originating from the objects along the side of the roads and can be expected to result in more accurate predictions and smaller prediction intervals.</ce:para>
                     </ce:section>
                     <ce:section id="s0155" view="all">
                        <ce:label>5.2.3</ce:label>
                        <ce:section-title id="st0170">Classification accuracy</ce:section-title>
                        <ce:para id="p0245" view="all">RQI classes estimated based on the predicted IRI resulted in an overall accuracy of 83%. As illustrated in <ce:cross-ref id="cf0420" refid="f0085">Fig. 17</ce:cross-ref>
                           <ce:float-anchor refid="f0085"/>, the model performs significantly better for the pavements in Good and Fair condition. When compared to the classification accuracy of 87% as reported for the L-band SAR data based binary logit model presented in Suanpaga and Yoshikazu [<ce:cross-ref id="cf0425" refid="bb0100">20</ce:cross-ref>], the Deep Neural Network model underperforms for the extreme categories. This performance was observed to be highly influenced by the sample size of the corresponding categories. Classification accuracy sharply dropped to 31% for the Poor RQI class, as the representation of this class is only 1.4% in the dataset. The extreme classes constituted &lt;1% of dataset and, as a result, the model rarely classifies a segment as very poor or very good. While the model performs satisfactorily for the common range of IRI values, a more balanced dataset will improve the model performance over a greater range of RQI classes.</ce:para>
                     </ce:section>
                  </ce:section>
                  <ce:section id="s0160" view="all">
                     <ce:label>5.3</ce:label>
                     <ce:section-title id="st0175">Model deployment</ce:section-title>
                     <ce:para id="p0250" view="all">To facilitate an easy deployment of the developed models by transportation agencies worldwide, a program with a graphical user interface was developed using Python's Tkinter library. Given a properly processed SAR image and pavement features, the SAR based Condition (SAR<ce:glyph name="sbnd"/>C) evaluation tool (<ce:cross-ref id="cf0430" refid="f0090">Fig. 18</ce:cross-ref>
                        <ce:float-anchor refid="f0090"/>) estimates IRI, associated prediction intervals, and RQI class for the road segments of interest. The user manual of the program describes in detail the steps of processing SAR images with an example following the proposed framework. The user manual can be accessed here: <ce:inter-ref id="ir0005" xlink:href="https://github.com/infra-health/sar-c" xlink:type="simple">https://github.com/infra-health/sar-c</ce:inter-ref>
                     </ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0165" view="all">
                  <ce:label>6</ce:label>
                  <ce:section-title id="st0180">Conclusions and recommendations</ce:section-title>
                  <ce:para id="p0255" view="all">This paper introduces a novel framework to estimate pavement IRI using deep learning and spaceborne SAR imagery. A case study analyzing the trunk highway network in Minnesota was undertaken to identify the improvements in SAR image processing for pavement applications as well as to demonstrate the predictive performance of the developed deep learning tool. Specific conclusions and recommendations derived from this project are summarized below.</ce:para>
                  <ce:section id="s0170" view="all">
                     <ce:label>6.1</ce:label>
                     <ce:section-title id="st0185">Conclusions</ce:section-title>
                     <ce:para id="p0260" view="all">
                        <ce:list id="l0025">
                           <ce:list-item id="li0045">
                              <ce:label>•</ce:label>
                              <ce:para id="p0265" view="all">Sentinel-1 SAR images were found to have a strong potential in quantifying pavement roughness. While it is not as highly accurate as the IRI measured by digital inspection vehicles, it can be used to evaluate the condition of local, ancillary, or low priority roads which are not typically monitored, and where a very accuracy is not necessarily needed.</ce:para>
                           </ce:list-item>
                           <ce:list-item id="li0050">
                              <ce:label>•</ce:label>
                              <ce:para id="p0270" view="all">The proposed framework is highly capable in improving SAR image processing for pavement applications as it effectively addresses the challenges of removing traffic noises from pavements, suppressing speckles without comprising the road features, and eliminating the effects of terrain on SAR backscatters.</ce:para>
                           </ce:list-item>
                           <ce:list-item id="li0055">
                              <ce:label>•</ce:label>
                              <ce:para id="p0275" view="all">The deep learning tool can predict IRI with an <ce:italic>MAE</ce:italic> ranging from 13.9 to 14.6 in./mile. The associated prediction intervals were found to capture 81% of the actual IRI values within their upper and lower limits. The tool is also effective at classifying RQI classes, with an overall classification accuracy of 83%.</ce:para>
                           </ce:list-item>
                        </ce:list>
                     </ce:para>
                  </ce:section>
                  <ce:section id="s0175" view="all">
                     <ce:label>6.2</ce:label>
                     <ce:section-title id="st0190">Recommendations</ce:section-title>
                     <ce:para id="p0280" view="all">
                        <ce:list id="l0030">
                           <ce:list-item id="li0060">
                              <ce:label>•</ce:label>
                              <ce:para id="p0285" view="all">The VV polarization image was found to be more sensitive to pavement roughness as compared to the VH polarization.</ce:para>
                           </ce:list-item>
                           <ce:list-item id="li0065">
                              <ce:label>•</ce:label>
                              <ce:para id="p0290" view="all">Refined Lee filter is recommended to remove speckles, as it preserves the edges and texture of linear road features.</ce:para>
                           </ce:list-item>
                           <ce:list-item id="li0070">
                              <ce:label>•</ce:label>
                              <ce:para id="p0295" view="all">The analysis of SAR images should include a radiometric terrain correction to remove the effect of slopes on SAR backscatters.</ce:para>
                           </ce:list-item>
                           <ce:list-item id="li0075">
                              <ce:label>•</ce:label>
                              <ce:para id="p0300" view="all">Identifying an appropriate time window for collecting SAR images over a specific region is critical to avoid the effects of weather on SAR backscatters.</ce:para>
                           </ce:list-item>
                           <ce:list-item id="li0080">
                              <ce:label>•</ce:label>
                              <ce:para id="p0305" view="all">The generation of a minimum intensity image from a stack of SAR images is an effective solution to eliminate traffic noises from the pavement pixels.</ce:para>
                           </ce:list-item>
                        </ce:list>
                     </ce:para>
                  </ce:section>
                  <ce:section id="s0180" view="all">
                     <ce:label>6.3</ce:label>
                     <ce:section-title id="st0195">Limitations and future research</ce:section-title>
                     <ce:para id="p0310" view="all">The proposed framework is currently limited by the resolution of Sentinel-1 images as in many cases the width of the roads can be less than the size of the pixels. This raises an interesting future avenue for research using high resolution X-band SAR images captured by the Cosmo-SkyMed satellite.</ce:para>
                     <ce:para id="p0315" view="all">The limitations of the deep learning tool in predicting higher IRI values can also be addressed by including examples in the dataset from a wider range of road classes. It will be particularly important to include examples of pavement in Very Good and Very Poor condition to have a more balanced dataset.</ce:para>
                     <ce:para id="p0320" view="all">Finally, calibrating and testing the model for roads with different physical attributes (e.g., wider highways, narrower ancillary roads) and geographic locations using transfer learning will enhance the scale of implementation of the SAR-C software developed in this project.</ce:para>
                  </ce:section>
               </ce:section>
               <ce:section id="s0185" view="all">
                  <ce:section-title id="st0200">Funding</ce:section-title>
                  <ce:para id="p0325" view="all">This work was supported by the <ce:grant-sponsor id="gts0005" sponsor-id="https://doi.org/10.13039/100004960" xlink:type="simple" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor">Minnesota Department of Transportation</ce:grant-sponsor> [MnDOT Contract Number: <ce:grant-number id="gtn0005" refid="gts0005">1045229</ce:grant-number>]. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the Minnesota Department of Transportation.</ce:para>
               </ce:section>
            </ce:sections>
            <ce:conflict-of-interest id="coi0005" view="all">
               <ce:section-title id="st0205">Declaration of Competing Interest</ce:section-title>
               <ce:para id="p0330" view="all">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</ce:para>
            </ce:conflict-of-interest>
            <ce:acknowledgment id="ac0005" view="all">
               <ce:section-title id="st0210">Acknowledgements</ce:section-title>
               <ce:para id="p0335" view="all">The authors would like to acknowledge Peter Jenkins, Joshua Stearns, Shelly Pedersen, and Michael Cremin of Minnesota Department of Transportation for their assistance with data collection and inquiry.</ce:para>
            </ce:acknowledgment>
         </body>
         <tail view="all">
            <ce:bibliography id="bi0005" view="all">
               <ce:section-title id="st0215">References</ce:section-title>
               <ce:bibliography-sec id="bs0005" view="all">
                  <ce:bib-reference id="bb0005">
                     <ce:label>[1]</ce:label>
                     <sb:reference id="rf0005">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>ASCE</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Report Card for America’s Infrastructure, 2021</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2021</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0010">ASCE, 2021 Report Card for America'’s Infrastructure, 2021.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0010">
                     <ce:label>[2]</ce:label>
                     <sb:reference id="rf0010">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>TRIP</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Key Facts about America's Surface Transportation System and Federal Funding</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:e-host>
                              <ce:inter-ref xlink:href="http://www.tripnet.org/docs/Fact_Sheet_National.pdf" id="ir0010" xlink:type="simple">http://www.tripnet.org/docs/Fact_Sheet_National.pdf</ce:inter-ref>
                              <sb:date>2018</sb:date>
                           </sb:e-host>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0015">TRIP, Key Facts About America'’s Surface Transportation System and Federal Funding, (2018). http://www.tripnet.org/docs/Fact_Sheet_National.pdf.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0015">
                     <ce:label>[3]</ce:label>
                     <sb:reference id="rf0015">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>FHWA</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Highway Performance Monitoring System Field Manual</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2016</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0020">FHWA, Highway Performance Monitoring System Field Manual, 2016.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0020">
                     <ce:label>[4]</ce:label>
                     <sb:reference id="rf0020">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Shahi</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>H.Z.M.</ce:given-name>
                                 <ce:surname>Shafri</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>E.</ce:given-name>
                                 <ce:surname>Taherzadeh</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Mansor</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>R.</ce:given-name>
                                 <ce:surname>Muniandy</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A novel spectral index to automatically extract road networks from WorldView-2 satellite imagery</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Egypt. J. Remote Sens. Sp. Sci.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>18</sb:volume-nr>
                              </sb:series>
                              <sb:date>2015</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>27</sb:first-page>
                              <sb:last-page>33</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/j.ejrs.2014.12.003</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0025">K. Shahi, H.Z.M. Shafri, E. Taherzadeh, S. Mansor, R. Muniandy, A novel spectral index to automatically extract road networks from WorldView-2 satellite imagery, Egypt. J. Remote Sens. Sp. Sci. 18 (2015) 27–33. doi:10.1016/j.ejrs.2014.12.003.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0025">
                     <ce:label>[5]</ce:label>
                     <sb:reference id="rf0025">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>C.</ce:given-name>
                                 <ce:surname>Mettas</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Themistocleous</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Neocleous</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Christofe</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Pilakoutas</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>D.</ce:given-name>
                                 <ce:surname>Hadjimitsis</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Monitoring asphalt pavement damages using remote sensing techniques</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:edited-book>
                              <sb:title>
                                 <sb:maintitle>Third Int. Conf. Remote Sens. Geoinf. Environ</sb:maintitle>
                              </sb:title>
                              <sb:book-series>
                                 <sb:series>
                                    <sb:volume-nr>9535</sb:volume-nr>
                                 </sb:series>
                              </sb:book-series>
                              <sb:date>2015</sb:date>
                           </sb:edited-book>
                           <sb:pages>
                              <sb:first-page>95350S</sb:first-page>
                           </sb:pages>
                           <ce:doi>10.1117/12.2195702</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0030">C. Mettas, K. Themistocleous, K. Neocleous, A. Christofe, K. Pilakoutas, D. Hadjimitsis, Monitoring asphalt pavement damages using remote sensing techniques, Third Int. Conf. Remote Sens. Geoinf. Environ. 9535 (2015) 95350S. doi:10.1117/12.2195702.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0030">
                     <ce:label>[6]</ce:label>
                     <sb:reference id="rf0030">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Li</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Faghri</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Ozden</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>Y.</ce:given-name>
                                 <ce:surname>Yue</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Economic feasibility study for pavement monitoring using synthetic aperture radar-based satellite remote sensing cost-benefit analysis</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Transp. Res. Rec.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>2645</sb:volume-nr>
                              </sb:series>
                              <sb:date>2017</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1</sb:first-page>
                              <sb:last-page>11</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.3141/2645-01</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0035">M. Li, A. Faghri, A. Ozden, Y. Yue, Economic feasibility study for pavement monitoring using synthetic aperture radar-based satellite remote sensing cost-benefit analysis, Transp. Res. Rec. 2645 (2017) 1–11. doi:10.3141/2645-01.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0035">
                     <ce:label>[7]</ce:label>
                     <sb:reference id="rf0035">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>M.Z.</ce:given-name>
                                 <ce:surname>Bashar</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>C.</ce:given-name>
                                 <ce:surname>Torres-Machi</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Performance of machine learning algorithms in predicting the pavement international roughness index</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Transp. Res. Rec. J. Transp. Res. Board</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>2675</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>5</sb:issue-nr>
                              <sb:date>2021</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>226</sb:first-page>
                              <sb:last-page>237</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1177/0361198120986171</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0040">M.Z. Bashar, C. Torres-Machi, Performance of Machine Learning Algorithms in Predicting the Pavement International Roughness Index, Transp. Res. Rec. J. Transp. Res. Board. (2021).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0040">
                     <ce:label>[8]</ce:label>
                     <sb:reference id="rf0040">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>C.</ce:given-name>
                                 <ce:surname>Koch</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Georgieva</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>V.</ce:given-name>
                                 <ce:surname>Kasireddy</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>B.</ce:given-name>
                                 <ce:surname>Akinci</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>P.</ce:given-name>
                                 <ce:surname>Fieguth</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Adv. Eng. Inform.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>29</sb:volume-nr>
                              </sb:series>
                              <sb:date>2015</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>196</sb:first-page>
                              <sb:last-page>210</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/j.aei.2015.01.008</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0045">C. Koch, K. Georgieva, V. Kasireddy, B. Akinci, P. Fieguth, A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure, Adv. Eng. Informatics. 29 (2015) 196–210. doi:10.1016/j.aei.2015.01.008.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0045">
                     <ce:label>[9]</ce:label>
                     <sb:reference id="rf0045">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Li</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>G.</ce:given-name>
                                 <ce:surname>Yin</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>X.</ce:given-name>
                                 <ce:surname>Wang</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>W.</ce:given-name>
                                 <ce:surname>Yan</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Automated decision making in highway pavement preventive maintenance based on deep learning</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Autom. Constr.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>135</sb:volume-nr>
                              </sb:series>
                              <sb:date>2022</sb:date>
                           </sb:issue>
                           <sb:article-number>104111</sb:article-number>
                           <ce:doi>10.1016/J.AUTCON.2021.104111</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0050">J. Li, G. Yin, X. Wang, W. Yan, Automated decision making in highway pavement preventive maintenance based on deep learning, Autom. Constr. 135 (2022) 104111. doi:10.1016/J.AUTCON.2021.104111.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0050">
                     <ce:label>[10]</ce:label>
                     <sb:reference id="rf0050">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>Z.</ce:given-name>
                                 <ce:surname>Tong</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Gao</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Sha</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>L.</ce:given-name>
                                 <ce:surname>Hu</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Li</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Convolutional neural network for asphalt pavement surface texture analysis</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Comput. Civ. Infrastruct. Eng.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>33</sb:volume-nr>
                              </sb:series>
                              <sb:date>2018</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1056</sb:first-page>
                              <sb:last-page>1072</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1111/MICE.12406</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0055">Z. Tong, J. Gao, A. Sha, L. Hu, S. Li, Convolutional Neural Network for Asphalt Pavement Surface Texture Analysis, Comput. Civ. Infrastruct. Eng. 33 (2018) 1056–1072. doi:10.1111/MICE.12406.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0055">
                     <ce:label>[11]</ce:label>
                     <sb:reference id="rf0055">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>A.G.</ce:given-name>
                                 <ce:surname>Batrakova</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>D.O.</ce:given-name>
                                 <ce:surname>Batrakov</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.S.</ce:given-name>
                                 <ce:surname>Antyufeyeva</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Pavement deterioration model based on GPR datasets</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Roads Bridg. - Drog. i Most.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>17</sb:volume-nr>
                              </sb:series>
                              <sb:date>2018</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>55</sb:first-page>
                              <sb:last-page>71</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.7409/RABDIM.018.004</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0060">A.G. Batrakova, D.O. Batrakov, M.S. Antyufeyeva, Pavement deterioration model based on GPR datasets, Roads Bridg. - Drog. i Most. 17 (2018) 55–71. doi:10.7409/RABDIM.018.004.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0060">
                     <ce:label>[12]</ce:label>
                     <sb:reference id="rf0060">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>D.O.</ce:given-name>
                                 <ce:surname>Batrakov</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.G.</ce:given-name>
                                 <ce:surname>Batrakova</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.N.</ce:given-name>
                                 <ce:surname>Urdzik</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>V.R.</ce:given-name>
                                 <ce:surname>Danielyan</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Nondestructive diagnostics and detection of subsurface cracks in non-rigid pavements with GPR</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>DIAGNOSTYKA.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>22</sb:volume-nr>
                              </sb:series>
                              <sb:date>2021</sb:date>
                           </sb:issue>
                           <ce:doi>10.29354/diag/137915</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0065">D.O. Batrakov, A.G. Batrakova, S.N. Urdzik, V.R. Danielyan, Nondestructive Diagnostics and Detection Of Subsurface Cracks In Non-Rigid Pavements With GPR, DIAGNOSTYKA. 22 (2021). doi:10.29354/diag/137915.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0065">
                     <ce:label>[13]</ce:label>
                     <sb:reference id="rf0065">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>Z.</ce:given-name>
                                 <ce:surname>Tong</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Gao</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>H.</ce:given-name>
                                 <ce:surname>Zhang</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Recognition, location, measurement, and 3D reconstruction of concealed cracks using convolutional neural networks</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Constr. Build. Mater.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>146</sb:volume-nr>
                              </sb:series>
                              <sb:date>2017</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>775</sb:first-page>
                              <sb:last-page>787</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/j.conbuildmat.2017.04.097</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0070">Z. Tong, J. Gao, H. Zhang, Recognition, location, measurement, and 3D reconstruction of concealed cracks using convolutional neural networks, Constr. Build. Mater. 146 (2017) 775–787. doi:10.1016/j.conbuildmat.2017.04.097.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0070">
                     <ce:label>[14]</ce:label>
                     <sb:reference id="rf0070">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>Y.</ce:given-name>
                                 <ce:surname>Ma</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Elseifi</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>N.</ce:given-name>
                                 <ce:surname>Dhakal</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Bashar</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>Z.</ce:given-name>
                                 <ce:surname>Zhang</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Non-destructive detection of asphalt concrete stripping damage using ground penetrating radar</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Transp. Res. Rec.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>2675</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>10</sb:issue-nr>
                              <sb:date>2021</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>938</sb:first-page>
                              <sb:last-page>947</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1177/03611981211014199</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0075">Y. Ma, M. Elseifi, N. Dhakal, M. Bashar, Z. Zhang, Non-Destructive Detection of Asphalt Concrete Stripping Damage Using Ground Penetrating Radar, Transp. Res. Rec. (2021).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0075">
                     <ce:label>[15]</ce:label>
                     <sb:reference id="rf0075">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>I.L.</ce:given-name>
                                 <ce:surname>Al-Qadi</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Lahouar</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Measuring layer thicknesses with GPR – theory to practice</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Constr. Build. Mater.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>19</sb:volume-nr>
                              </sb:series>
                              <sb:date>2005</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>763</sb:first-page>
                              <sb:last-page>772</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/J.CONBUILDMAT.2005.06.005</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0080">I.L. Al-Qadi, S. Lahouar, Measuring layer thicknesses with GPR – Theory to practice, Constr. Build. Mater. 19 (2005) 763–772. doi:10.1016/J.CONBUILDMAT.2005.06.005.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0080">
                     <ce:label>[16]</ce:label>
                     <sb:reference id="rf0080">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>C.</ce:given-name>
                                 <ce:surname>Plati</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Loizos</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Estimation of in-situ density and moisture content in HMA pavements based on GPR trace reflection amplitude using different frequencies</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>J. Appl. Geophys.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>97</sb:volume-nr>
                              </sb:series>
                              <sb:date>2013</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>3</sb:first-page>
                              <sb:last-page>10</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/j.jappgeo.2013.04.007</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0085">C. Plati, A. Loizos, Estimation of in-situ density and moisture content in HMA pavements based on GPR trace reflection amplitude using different frequencies, J. Appl. Geophys. 97 (2013) 3–10. doi:10.1016/j.jappgeo.2013.04.007.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0085">
                     <ce:label>[17]</ce:label>
                     <sb:reference id="rf0085">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>H.S.</ce:given-name>
                                 <ce:surname>Munawar</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.W.A.</ce:given-name>
                                 <ce:surname>Hammad</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.T.</ce:given-name>
                                 <ce:surname>Waller</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A review on flood management technologies related to image processing and machine learning</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Autom. Constr.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>132</sb:volume-nr>
                              </sb:series>
                              <sb:date>2021</sb:date>
                           </sb:issue>
                           <sb:article-number>103916</sb:article-number>
                           <ce:doi>10.1016/J.AUTCON.2021.103916</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0090">H.S. Munawar, A.W.A. Hammad, S.T. Waller, A review on flood management technologies related to image processing and machine learning, Autom. Constr. 132 (2021) 103916. doi:10.1016/J.AUTCON.2021.103916.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0090">
                     <ce:label>[18]</ce:label>
                     <sb:reference id="rf0090">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Fagrhi</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Ozden</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Satellite Assessment and Monitoring for Pavement Management</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2015</sb:date>
                              <sb:publisher>
                                 <sb:name>Newark</sb:name>
                                 <sb:location>Delaware</sb:location>
                              </sb:publisher>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0095">A. Fagrhi, A. Ozden, Satellite Assessment and Monitoring for Pavement Management, Newark, Delaware, 2015.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0095">
                     <ce:label>[19]</ce:label>
                     <sb:reference id="rf0095">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Ozden</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Faghri</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Li</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Tabrizi</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Evaluation of synthetic aperture radar satellite remote sensing for pavement and infrastructure monitoring</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Proc. Eng.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>145</sb:volume-nr>
                              </sb:series>
                              <sb:date>2016</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>752</sb:first-page>
                              <sb:last-page>759</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/j.proeng.2016.04.098</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0100">A. Ozden, A. Faghri, M. Li, K. Tabrizi, Evaluation of Synthetic Aperture Radar Satellite Remote Sensing for Pavement and Infrastructure Monitoring, Procedia Eng. 145 (2016) 752–759. doi:10.1016/j.proeng.2016.04.098.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0100">
                     <ce:label>[20]</ce:label>
                     <sb:reference id="rf0100">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>W.</ce:given-name>
                                 <ce:surname>Suanpaga</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Yoshikazu</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Riding quality model for asphalt pavement monitoring using phase array type L-band synthetic aperture radar (PALSAR)</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Remote Sens.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>2</sb:volume-nr>
                              </sb:series>
                              <sb:date>2010</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>2531</sb:first-page>
                              <sb:last-page>2546</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.3390/rs2112531</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0105">W. Suanpaga, K. Yoshikazu, Riding quality model for asphalt pavement monitoring using phase array type L-band synthetic aperture radar (PALSAR), Remote Sens. 2 (2010) 2531–2546. doi:10.3390/rs2112531.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0105">
                     <ce:label>[21]</ce:label>
                     <sb:reference id="rf0105">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Karimzadeh</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Matsuoka</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Remote sensing X-band SAR data for land subsidence and pavement monitoring</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Sensors.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>20</sb:volume-nr>
                              </sb:series>
                              <sb:date>2020</sb:date>
                           </sb:issue>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0110">S. Karimzadeh, M. Matsuoka, Remote Sensing X-Band SAR Data for Land Subsidence and Pavement Monitoring, Sensors. 20 (2020).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0110">
                     <ce:label>[22]</ce:label>
                     <sb:reference id="rf0110">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>F.J.</ce:given-name>
                                 <ce:surname>Meyer</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Spaceborne synthetic aperture radar – Principles, data access, and basic processing techniques</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:edited-book>
                              <sb:editors>
                                 <sb:editor>
                                    <ce:given-name>A.</ce:given-name>
                                    <ce:surname>Flores</ce:surname>
                                 </sb:editor>
                                 <sb:editor>
                                    <ce:given-name>K.</ce:given-name>
                                    <ce:surname>Herndon</ce:surname>
                                 </sb:editor>
                                 <sb:editor>
                                    <ce:given-name>R.</ce:given-name>
                                    <ce:surname>Thapa</ce:surname>
                                 </sb:editor>
                                 <sb:editor>
                                    <ce:given-name>E.</ce:given-name>
                                    <ce:surname>Cherrington</ce:surname>
                                 </sb:editor>
                              </sb:editors>
                              <sb:title>
                                 <sb:maintitle>SAR Handb. Compr. Methodol. For. Monit. Biomass Estim</sb:maintitle>
                              </sb:title>
                              <sb:date>2019</sb:date>
                              <sb:publisher>
                                 <sb:name>NASA</sb:name>
                              </sb:publisher>
                           </sb:edited-book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0115">F.J. Meyer, Spaceborne Synthetic Aperture Radar – Principles, Data Access, and Basic Processing Techniques, in: A. Flores, K. Herndon, R. Thapa, E. Cherrington (Eds.), SAR Handb. Compr. Methodol. For. Monit. Biomass Estim., NASA, 2019.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0115">
                     <ce:label>[23]</ce:label>
                     <sb:reference id="rf0115">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Jaybhay</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>R.</ce:given-name>
                                 <ce:surname>Shastri</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A study of speckle noise reduction filters, signal image process</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>An Int. J.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>6</sb:volume-nr>
                              </sb:series>
                              <sb:date>2015</sb:date>
                           </sb:issue>
                           <ce:doi>10.5121/sipij.2015.6306</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0120">J. Jaybhay, R. Shastri, A Study of Speckle Noise Reduction Filters, Signal Image Process. An Int. J. 6 (2015). doi:10.5121/sipij.2015.6306.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0120">
                     <ce:label>[24]</ce:label>
                     <sb:reference id="rf0120">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>F.J.</ce:given-name>
                                 <ce:surname>Meyer</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>O.A.</ce:given-name>
                                 <ce:surname>Ajadi</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>E.</ce:given-name>
                                 <ce:surname>Hoppe</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Studying the applicability of X-band SAR data to the network-scale mapping of pavement roughness on US roads</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Remote Sens.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>12</sb:volume-nr>
                              </sb:series>
                              <sb:date>2020</sb:date>
                           </sb:issue>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0125">F.J. Meyer, O.A. Ajadi, E. Hoppe, Studying the Applicability of X-Band SAR Data to the Network-Scale Mapping of Pavement Roughness on US Roads, Remote Sens. 12 (2020).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0125">
                     <ce:label>[25]</ce:label>
                     <sb:reference id="rf0125">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>Copernicus Sentinel data</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Retrieved from ASF DAAC. Processed by ESA</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2019</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0130">Copernicus Sentinel data. Retrieved from ASF DAAC. Processed by ESA, (2019).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0130">
                     <ce:label>[26]</ce:label>
                     <sb:reference id="rf0130">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>T.R.</ce:given-name>
                                 <ce:surname>Crimmins</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Geometric filter for speckle reduction</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Appl. Opt.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>24</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>10</sb:issue-nr>
                              <sb:date>1985</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1438</sb:first-page>
                              <sb:last-page>1443</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1364/AO.24.001438</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0135">T.R. Crimmins, Geometric filter for speckle reduction, Appl. Opt. Vol. 24, Issue 10, Pp. 1438-1443. 24 (1985) 1438–1443. doi:10.1364/AO.24.001438.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0135">
                     <ce:label>[27]</ce:label>
                     <sb:reference id="rf0135">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Parrilli</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Poderico</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>C.V.</ce:given-name>
                                 <ce:surname>Angelino</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>L.</ce:given-name>
                                 <ce:surname>Verdoliva</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A nonlocal SAR image denoising algorithm based on LLMMSE wavelet shrinkage</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>IEEE Trans. Geosci. Remote Sens.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>50</sb:volume-nr>
                              </sb:series>
                              <sb:date>2012</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>606</sb:first-page>
                              <sb:last-page>616</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1109/TGRS.2011.2161586</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0140">S. Parrilli, M. Poderico, C.V. Angelino, L. Verdoliva, A nonlocal SAR image denoising algorithm based on LLMMSE wavelet shrinkage, IEEE Trans. Geosci. Remote Sens. 50 (2012) 606–616. doi:10.1109/TGRS.2011.2161586.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0140">
                     <ce:label>[28]</ce:label>
                     <sb:reference id="rf0140">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>C.</ce:given-name>
                                 <ce:surname>Oliver</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Quegan</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Understanding synthetic aperture radar images, Norwood</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>MA Artech House</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>1997</sb:volume-nr>
                              </sb:series>
                              <sb:issue-nr>53</sb:issue-nr>
                              <sb:date>1997</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1689</sb:first-page>
                              <sb:last-page>1699</sb:last-page>
                           </sb:pages>
                        </sb:host>
                        <sb:host>
                           <sb:e-host>
                              <ce:inter-ref xlink:href="https://books.google.com/books/about/Understanding_Synthetic_Aperture_Radar_I.html?id=IeGKe40S77AC" id="ir0015" xlink:type="simple">https://books.google.com/books/about/Understanding_Synthetic_Aperture_Radar_I.html?id=IeGKe40S77AC</ce:inter-ref>
                           </sb:e-host>
                        </sb:host>
                        <sb:comment>(accessed February 23, 2022)</sb:comment>
                     </sb:reference>
                     <ce:source-text id="se0145">C. Oliver, S. Quegan, Understanding synthetic aperture radar images, Norwood, MA Artech House, 1997. 53 (1997) 1689–1699. https://books.google.com/books/about/Understanding_Synthetic_Aperture_Radar_I.html?id=IeGKe40S77AC (accessed February 23, 2022).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0145">
                     <ce:label>[29]</ce:label>
                     <sb:reference id="rf0145">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>F.</ce:given-name>
                                 <ce:surname>Guo</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>G.</ce:given-name>
                                 <ce:surname>Zhang</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>Q.</ce:given-name>
                                 <ce:surname>Zhang</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>R.</ce:given-name>
                                 <ce:surname>Zhao</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Deng</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Xu</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Speckle suppression by weighted Euclidean distance anisotropic diffusion</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Remote Sens.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>10</sb:volume-nr>
                              </sb:series>
                              <sb:date>2018</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>722</sb:first-page>
                           </sb:pages>
                           <ce:doi>10.3390/RS10050722</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0150">F. Guo, G. Zhang, Q. Zhang, R. Zhao, M. Deng, K. Xu, Speckle Suppression by Weighted Euclidean Distance Anisotropic Diffusion, Remote Sens. 2018, Vol. 10, Page 722. 10 (2018) 722. doi:10.3390/RS10050722.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0150">
                     <ce:label>[30]</ce:label>
                     <sb:reference id="rf0150">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>G.</ce:given-name>
                                 <ce:surname>James</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>D.</ce:given-name>
                                 <ce:surname>Witten</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>T.</ce:given-name>
                                 <ce:surname>Hastie</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>R.</ce:given-name>
                                 <ce:surname>Tibshirani</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>An Introduction to Statistical Learning</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2013</sb:date>
                              <sb:publisher>
                                 <sb:name>Springer</sb:name>
                              </sb:publisher>
                           </sb:book>
                        </sb:host>
                        <sb:host>
                           <sb:e-host>
                              <ce:inter-ref xlink:href="http://faculty.marshall.usc.edu/gareth-james/ISL/book.html" id="ir0020" xlink:type="simple">http://faculty.marshall.usc.edu/gareth-james/ISL/book.html</ce:inter-ref>
                           </sb:e-host>
                        </sb:host>
                        <sb:comment>(accessed December 13, 2020)</sb:comment>
                     </sb:reference>
                     <ce:source-text id="se0155">G. James, D. Witten, T. Hastie, R. Tibshirani, An Introduction to Statistical Learning, Springer, 2013. http://faculty.marshall.usc.edu/gareth-james/ISL/book.html (accessed December 13, 2020).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0155">
                     <ce:label>[31]</ce:label>
                     <sb:reference id="rf0155">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>L.</ce:given-name>
                                 <ce:surname>Barua</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>B.</ce:given-name>
                                 <ce:surname>Zou</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Noruzoliaee</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.</ce:given-name>
                                 <ce:surname>Derrible</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A gradient boosting approach to understanding airport runway and taxiway pavement deterioration</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Int. J. Pavement Eng.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>22</sb:volume-nr>
                              </sb:series>
                              <sb:date>2021</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1673</sb:first-page>
                              <sb:last-page>1687</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1080/10298436.2020.1714616/FORMAT/EPUB</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0160">L. Barua, B. Zou, M. Noruzoliaee, S. Derrible, A gradient boosting approach to understanding airport runway and taxiway pavement deterioration, Int. J. Pavement Eng. 22 (2021) 1673–1687. doi:10.1080/10298436.2020.1714616/FORMAT/EPUB.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0160">
                     <ce:label>[32]</ce:label>
                     <sb:reference id="rf0160">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>D.</ce:given-name>
                                 <ce:surname>Chakraborty</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>H.</ce:given-name>
                                 <ce:surname>Elhegazy</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>H.</ce:given-name>
                                 <ce:surname>Elzarka</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>L.</ce:given-name>
                                 <ce:surname>Gutierrez</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>A novel construction cost prediction model using hybrid natural and light gradient boosting</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Adv. Eng. Inform.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>46</sb:volume-nr>
                              </sb:series>
                              <sb:date>2020</sb:date>
                           </sb:issue>
                           <sb:article-number>101201</sb:article-number>
                           <ce:doi>10.1016/J.AEI.2020.101201</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0165">D. Chakraborty, H. Elhegazy, H. Elzarka, L. Gutierrez, A novel construction cost prediction model using hybrid natural and light gradient boosting, Adv. Eng. Informatics. 46 (2020) 101201. doi:10.1016/J.AEI.2020.101201.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0165">
                     <ce:label>[33]</ce:label>
                     <sb:reference id="rf0165">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>G.</ce:given-name>
                                 <ce:surname>Sollazzo</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>T.F.</ce:given-name>
                                 <ce:surname>Fwa</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>G.</ce:given-name>
                                 <ce:surname>Bosurgi</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>An ANN model to correlate roughness and structural performance in asphalt pavements</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Constr. Build. Mater.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>134</sb:volume-nr>
                              </sb:series>
                              <sb:date>2017</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>684</sb:first-page>
                              <sb:last-page>693</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1016/j.conbuildmat.2016.12.186</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0170">G. Sollazzo, T.F. Fwa, G. Bosurgi, An ANN model to correlate roughness and structural performance in asphalt pavements, Constr. Build. Mater. 134 (2017) 684–693. doi:10.1016/j.conbuildmat.2016.12.186.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0170">
                     <ce:label>[34]</ce:label>
                     <sb:reference id="rf0170">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>W.</ce:given-name>
                                 <ce:surname>Zeiada</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>S.A.</ce:given-name>
                                 <ce:surname>Dabous</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>K.</ce:given-name>
                                 <ce:surname>Hamad</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>R.</ce:given-name>
                                 <ce:surname>Al-Ruzouq</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.A.</ce:given-name>
                                 <ce:surname>Khalil</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Machine learning for pavement performance modelling in warm climate regions</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Arab. J. Sci. Eng.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>45</sb:volume-nr>
                              </sb:series>
                              <sb:date>2020</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>4091</sb:first-page>
                              <sb:last-page>4109</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1007/s13369-020-04398-6</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0175">W. Zeiada, S.A. Dabous, K. Hamad, R. Al-Ruzouq, M.A. Khalil, Machine Learning for Pavement Performance Modelling in Warm Climate Regions, Arab. J. Sci. Eng. 45 (2020) 4091–4109. doi:10.1007/s13369-020-04398-6.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0175">
                     <ce:label>[35]</ce:label>
                     <sb:reference id="rf0175">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>N.</ce:given-name>
                                 <ce:surname>Kargah-Ostadi</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Comparison of machine learning techniques for developing performance prediction models Nima</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Comput. Civ. Build. Eng.</sb:maintitle>
                                 </sb:title>
                              </sb:series>
                              <sb:date>2014</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>1222</sb:first-page>
                              <sb:last-page>1229</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1061/9780784413616.053</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0180">N. Kargah-Ostadi, Comparison of Machine Learning Techniques for Developing Performance Prediction Models Nima, Comput. Civ. Build. Eng. (2014) 1222–1229. doi:10.1061/9780784413616.053.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0180">
                     <ce:label>[36]</ce:label>
                     <sb:reference id="rf0180">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>M.S.</ce:given-name>
                                 <ce:surname>Yamany</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>T.U.</ce:given-name>
                                 <ce:surname>Saeed</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>M.</ce:given-name>
                                 <ce:surname>Volovski</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>A.</ce:given-name>
                                 <ce:surname>Ahmed</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Characterizing the performance of interstate flexible pavements using artificial neural networks and random parameters regression</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>J. Infrastruct. Syst.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>26</sb:volume-nr>
                              </sb:series>
                              <sb:date>2020</sb:date>
                           </sb:issue>
                           <ce:doi>10.1061/(ASCE)IS.1943-555X.0000542</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0185">M.S. Yamany, T.U. Saeed, M. Volovski, A. Ahmed, Characterizing the Performance of Interstate Flexible Pavements Using Artificial Neural Networks and Random Parameters Regression, J. Infrastruct. Syst. 26 (2020). doi:10.1061/(ASCE)IS.1943-555X.0000542.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0185">
                     <ce:label>[37]</ce:label>
                     <sb:reference id="rf0185">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>H.</ce:given-name>
                                 <ce:surname>Ziari</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Sobhani</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>J.</ce:given-name>
                                 <ce:surname>Ayoubinejad</ce:surname>
                              </sb:author>
                              <sb:author>
                                 <ce:given-name>T.</ce:given-name>
                                 <ce:surname>Hartmann</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Prediction of IRI in short and long terms for flexible pavements: ANN and GMDH methods</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Int. J. Pavement Eng.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>17</sb:volume-nr>
                              </sb:series>
                              <sb:date>2016</sb:date>
                           </sb:issue>
                           <sb:pages>
                              <sb:first-page>776</sb:first-page>
                              <sb:last-page>788</sb:last-page>
                           </sb:pages>
                           <ce:doi>10.1080/10298436.2015.1019498</ce:doi>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0190">H. Ziari, J. Sobhani, J. Ayoubinejad, T. Hartmann, Prediction of IRI in short and long terms for flexible pavements: ANN and GMDH methods, Int. J. Pavement Eng. 17 (2016) 776–788. doi:10.1080/10298436.2015.1019498.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0190">
                     <ce:label>[38]</ce:label>
                     <sb:reference id="rf0190">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>MnDOT</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Pavement Condition Annual Report, 2019</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2019</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0195">MnDOT, 2019 Pavement Condition Annual Report, 2019.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0195">
                     <ce:label>[39]</ce:label>
                     <sb:reference id="rf0195">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:given-name>M.W.</ce:given-name>
                                 <ce:surname>Sayers</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>On the calculation of international roughness index from longitudinal road profile</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:issue>
                              <sb:series>
                                 <sb:title>
                                    <sb:maintitle>Transp. Res. Rec.</sb:maintitle>
                                 </sb:title>
                                 <sb:volume-nr>1501</sb:volume-nr>
                              </sb:series>
                              <sb:date>1995</sb:date>
                           </sb:issue>
                        </sb:host>
                        <sb:host>
                           <sb:e-host>
                              <ce:inter-ref xlink:href="https://trid.trb.org/view/452992" id="ir0025" xlink:type="simple">https://trid.trb.org/view/452992</ce:inter-ref>
                           </sb:e-host>
                        </sb:host>
                        <sb:comment>(accessed July 10, 2022)</sb:comment>
                     </sb:reference>
                     <ce:source-text id="se0200">M.W. Sayers, On the calculation of International Roughness Index from Longitudinal Road Profile, Transp. Res. Rec. 1501 (1995). https://trid.trb.org/view/452992 (accessed July 10, 2022).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0200">
                     <ce:label>[40]</ce:label>
                     <sb:reference id="rf0200">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>Michigan Department of Transportation</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Asset Management Background International Roughness Index (IRI)</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2017</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0205">Michigan Department of Transportation, Asset Management Background International Roughness Index (IRI), 2017.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0205">
                     <ce:label>[41]</ce:label>
                     <sb:reference id="rf0205">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>MnDOT</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>MnDOT Pavement Distress Identification Manual</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2011</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0210">MnDOT, MnDOT Pavement Distress Identification Manual, 2011.</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0210">
                     <ce:label>[42]</ce:label>
                     <sb:reference id="rf0210">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>ASF DAAC</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Contains Modified Copernicus Sentinel Data, Processed by ESA</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2021</sb:date>
                           </sb:book>
                        </sb:host>
                     </sb:reference>
                     <ce:source-text id="se0215">ASF DAAC, Contains modified Copernicus Sentinel data, processed by ESA., (2021).</ce:source-text>
                  </ce:bib-reference>
                  <ce:bib-reference id="bb0215">
                     <ce:label>[43]</ce:label>
                     <sb:reference id="rf0215">
                        <sb:contribution langtype="en">
                           <sb:authors>
                              <sb:author>
                                 <ce:surname>MnDNR</ce:surname>
                              </sb:author>
                           </sb:authors>
                           <sb:title>
                              <sb:maintitle>Minneapolis/St. Paul Climate Data Snow Data Resources</sb:maintitle>
                           </sb:title>
                        </sb:contribution>
                        <sb:host>
                           <sb:book>
                              <sb:date>2022</sb:date>
                              <sb:publisher>
                                 <sb:name>Minnesota Dep. Nat. Resour</sb:name>
                              </sb:publisher>
                           </sb:book>
                        </sb:host>
                        <sb:host>
                           <sb:e-host>
                              <ce:inter-ref xlink:href="https://www.dnr.state.mn.us/climate/twin_cities/snowfall.html" id="ir0030" xlink:type="simple">https://www.dnr.state.mn.us/climate/twin_cities/snowfall.html</ce:inter-ref>
                           </sb:e-host>
                        </sb:host>
                        <sb:comment>(accessed February 21, 2022)</sb:comment>
                     </sb:reference>
                     <ce:source-text id="se0220">MnDNR, Minneapolis/St. Paul Climate Data Snow Data Resources, Minnesota Dep. Nat. Resour. (2022). https://www.dnr.state.mn.us/climate/twin_cities/snowfall.html (accessed February 21, 2022).</ce:source-text>
                  </ce:bib-reference>
               </ce:bibliography-sec>
            </ce:bibliography>
         </tail>
      </article>
   </xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>